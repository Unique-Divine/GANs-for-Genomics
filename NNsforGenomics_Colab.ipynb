{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NNsforGenomics_Colab.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bkh0Z3vEJuj1"
      },
      "source": [
        "For faster development speed, type `Ctrl + M, H` to view Google Colab keyboard shortcuts."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BiOsYGGAGd5C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "288c606a-2e3c-4b2e-ab26-9215b5d22ef2"
      },
      "source": [
        "!pip install pytorch-lightning --quiet\r\n",
        "# !curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\r\n",
        "# !python pytorch-xla-env-setup.py --version nightly --apt-packages libomp5 libopenblas-dev\r\n",
        "!pip install sdv --quiet"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 675kB 8.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 276kB 34.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 829kB 29.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 102kB 9.9MB/s \n",
            "\u001b[?25h  Building wheel for PyYAML (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 71kB 4.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 51kB 5.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 12.4MB 322kB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1MB 44.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 225kB 47.9MB/s \n",
            "\u001b[?25h  Building wheel for xeger (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for exrex (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: rdt 0.2.10 has requirement pandas<1.1.5,>=1.1, but you'll have pandas 1.1.5 which is incompatible.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rwgUdFx9ZQIl"
      },
      "source": [
        "### Getting Started\n",
        "\n",
        "\n",
        "#### Mounting your Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ze4LOQG2ZoAk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ee03bfb-f21e-42e1-81de-31a20f344f60"
      },
      "source": [
        "# np-pd-mpl\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns; sns.set()\n",
        "from numpy.lib.ufunclike import _deprecate_out_named_y\n",
        "\n",
        "# Neural network packages\n",
        "import torch\n",
        "import torch.nn as nn \n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data\n",
        "import torch.optim\n",
        "import pytorch_lightning as pl \n",
        "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
        "\n",
        "# Built-in\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "import copy\n",
        "import random\n",
        "import pickle\n",
        "from typing import List, Tuple, Dict, Any\n",
        "import logging\n",
        "logging.getLogger('lightning').setLevel(0)\n",
        "\n",
        "# sklearn\n",
        "from sklearn import feature_selection\n",
        "import sklearn.preprocessing\n",
        "import sklearn.metrics\n",
        "from sklearn import model_selection\n",
        "from sklearn import decomposition"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tIhoc7R7HhuB"
      },
      "source": [
        "Running the following cell will generate a message asking you to click on a link where you'll obtain an authorization code.\r\n",
        "\r\n",
        "Paste that authorization code into the text box that appears below to access Google Drive from this notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5908d_KoaoH3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17928314-0629-41d0-9c38-16c3c9c97213"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X8J16t4dZpOp",
        "outputId": "106d6aff-47c0-4b1f-db94-3de948ba10f2"
      },
      "source": [
        "!cd \"/content/gdrive/MyDrive/\" && ls # Displays directories in MyDrive/"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " ApTSi\t\t    Education\t'School-Related Planning'   地位を申し込む\n",
            "'Colab Notebooks'   Other\t SCIP\n",
            " Data\t\t    Recordings\t temp\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zJ2O5DloaWc0",
        "outputId": "12ba7b73-b0b8-45d2-c831-623a7f54ddba"
      },
      "source": [
        "dir_path = os.path.join(\"/content/gdrive/MyDrive/Data\", \"NNsforGenomics\")\r\n",
        "os.path.exists(dir_path)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dqxOD3I5RLdi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72c8bb8a-f987-4e62-8b0d-4b6f045f38d9"
      },
      "source": [
        "!cd {dir_path} && ls"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ctgan  data  gans.py  neural_networks.py  preprocessing.py  __pycache__\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JhpAy83kdexm"
      },
      "source": [
        "import sys\r\n",
        "sys.path.append(dir_path)\r\n",
        "data_path = os.path.join(dir_path, \"data\")\r\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "35-fUvYtgGz9"
      },
      "source": [
        "import ctgan \n",
        "import preprocessing\n",
        "import gans"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ofTQcvraH8y5"
      },
      "source": [
        "class TabularDataset(torch.utils.data.Dataset): # inherit from torch\r\n",
        "    def __init__(self, X: np.ndarray, Y: np.ndarray):\r\n",
        "        X, Y = [arr.astype(float) for arr in [X, Y]]\r\n",
        "        self.X = torch.from_numpy(X)\r\n",
        "        self.Y = torch.from_numpy(Y.reshape(-1,1))\r\n",
        "\r\n",
        "        self.n_samples = X.shape[0]\r\n",
        "        if self.X.shape[0] != self.Y.shape[0]:\r\n",
        "            raise ValueError(\"Shape mismatch. X and Y should have the same \" \r\n",
        "                + \"number of rows\")\r\n",
        "\r\n",
        "    def __getitem__(self, idx):\r\n",
        "        return self.X[idx], self.Y[idx]\r\n",
        "    \r\n",
        "    def __len__(self):\r\n",
        "        return self.n_samples"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8N9wcDxiH1qu"
      },
      "source": [
        "class LitFFNN(pl.LightningModule):\r\n",
        "    # ----------------------------------\r\n",
        "    # Initialize constants and NN architecture\r\n",
        "    # ----------------------------------\r\n",
        "    def __init__(self, X: np.ndarray, Y: np.ndarray, \r\n",
        "                 data_dir: str = data_path, batch_size: int = 50, \r\n",
        "                 train_set: TabularDataset, val_set: TabularDataset, \r\n",
        "                 test_set: TabularDataset):\r\n",
        "        \"\"\" Feed-Forward Neural Network System\r\n",
        "        Args:\r\n",
        "            X (np.ndarray): Feature matrix \r\n",
        "            Y (np.ndarray): Target matrix\r\n",
        "        \"\"\"\r\n",
        "        super().__init__()\r\n",
        "        # TODO: train-val-test splits\r\n",
        "        self.X, self.Y = X, Y\r\n",
        "        self.n_features = self.X.shape[1]\r\n",
        "\r\n",
        "        # Hard-coded constants\r\n",
        "        self.loss_fn = nn.NLLLoss()\r\n",
        "        self.BATCH_SIZE = batch_size\r\n",
        "        self.lr = 1e-2\r\n",
        "        self.N_CLASSES = 3\r\n",
        "        \r\n",
        "        self.epoch = 0\r\n",
        "\r\n",
        "        # ----------------------------------\r\n",
        "        # Architecture\r\n",
        "        # ----------------------------------\r\n",
        "        self.D_IN = self.X.shape[1]\r\n",
        "        # D_h_in = int((2/3) * self.D_IN)\r\n",
        "        # D_h_out = int((1/3) * self.D_IN) \r\n",
        "        hidden_dim = int(np.sqrt(self.D_IN * self.N_CLASSES))\r\n",
        "        D_h_in = hidden_dim\r\n",
        "        D_h_out = hidden_dim\r\n",
        "\r\n",
        "        self.fc_layers = nn.Sequential(\r\n",
        "            nn.Linear(self.D_IN, D_h_in),\r\n",
        "                nn.LeakyReLU(),\r\n",
        "                nn.Dropout(p = 0.1),\r\n",
        "            nn.Linear(D_h_in, D_h_out),\r\n",
        "                nn.LeakyReLU(),\r\n",
        "                nn.Dropout(p = 0.2),\r\n",
        "            nn.Linear(D_h_out, self.N_CLASSES)\r\n",
        "        )\r\n",
        "\r\n",
        "        self.epoch_train_losses = []\r\n",
        "        self.epoch_val_losses = []\r\n",
        "        self.best_val_epoch = 0\r\n",
        "\r\n",
        "    def forward(self, x): \r\n",
        "        x = x.float()\r\n",
        "        x = self.fc_layers(x)\r\n",
        "        logits = F.log_softmax(input = x, dim = 1)\r\n",
        "        return logits\r\n",
        "\r\n",
        "    def configure_optimizers(self):\r\n",
        "        optimizer = torch.optim.Adam(\r\n",
        "            params = self.parameters(), lr = self.lr)\r\n",
        "        return optimizer\r\n",
        "\r\n",
        "    # ----------------------------------\r\n",
        "    # Training, validation, and test steps\r\n",
        "    # ----------------------------------\r\n",
        "\r\n",
        "    def training_step(self, batch, batch_idx):\r\n",
        "        x, y = batch\r\n",
        "        y = y.flatten().long()\r\n",
        "        logits = self(x) \r\n",
        "        loss = self.loss_fn(logits, y)\r\n",
        "        self.log('train_loss', loss, on_step=True, on_epoch=True, \r\n",
        "                 prog_bar=True)\r\n",
        "        return loss\r\n",
        "\r\n",
        "    def validation_step(self, batch, batch_idx, val=True):\r\n",
        "        x, y = batch\r\n",
        "        y = y.flatten().long()\r\n",
        "        # compute loss\r\n",
        "        logits = self(x)\r\n",
        "        loss = self.loss_fn(logits, y)\r\n",
        "        self.log('val_loss', loss, on_step=True, on_epoch=True, \r\n",
        "                 prog_bar=True) # self.log interacts with TensorBoard\r\n",
        "        return loss\r\n",
        "\r\n",
        "    def test_step(self, batch, batch_idx):\r\n",
        "        return self.validation_step(batch, batch_idx, val = False)\r\n",
        "\r\n",
        "    def training_epoch_end(self, outputs: List[Any]):\r\n",
        "        outputs: List[torch.Tensor] = [list(d.values())[0] for d in outputs]\r\n",
        "        sum = torch.zeros(1, dtype=float).to(self.device)\r\n",
        "        for batch_idx, batch_loss in enumerate(outputs):\r\n",
        "            sum += batch_loss.to(self.device)\r\n",
        "        avg_batch_loss = (sum / batch_idx)\r\n",
        "        self.epoch_train_losses.append({avg_batch_loss[0].item()})\r\n",
        "\r\n",
        "    def validation_epoch_end(self, outputs: List[Any]):\r\n",
        "        sum = torch.zeros(1, dtype=float).to(self.device)\r\n",
        "        for batch_idx, batch_loss in enumerate(outputs):\r\n",
        "            sum += batch_loss.to(self.device)\r\n",
        "        avg_batch_loss = (sum / batch_idx) \r\n",
        "        self.epoch_val_losses.append({avg_batch_loss[0].item()})        \r\n",
        "\r\n",
        "    def custom_train(self, n_epochs, plot=True, verbose=False, plot_train=False):\r\n",
        "        train_loader = self.train_dl\r\n",
        "        val_loader = self.test_dl\r\n",
        "        device=self.device\r\n",
        "        self.network.to(device)\r\n",
        "\r\n",
        "        train_losses, val_losses = [], []\r\n",
        "        best_val_loss = np.infty\r\n",
        "        best_val_epoch = 0\r\n",
        "        early_stopping_buffer = 10\r\n",
        "        epoch = 0\r\n",
        "        best_params = None\r\n",
        "        for epoch in range(n_epochs):\r\n",
        "            train_loss, val_loss = 0.0, 0.0\r\n",
        "  \r\n",
        "            # Training\r\n",
        "            self.network.train()\r\n",
        "            for idx, batch in enumerate(train_loader):\r\n",
        "                self.optimizer.zero_grad() # clears paramter gradient buffers\r\n",
        "                inputs, targets = batch\r\n",
        "                # transfer batch data to computation device\r\n",
        "                inputs, targets = [\r\n",
        "                    tensor.to(device) for tensor in [inputs, targets]]\r\n",
        "                targets = targets.long() # converts dtype to Long\r\n",
        "                output = self.network(inputs)\r\n",
        "                loss = self.loss_fn(output, targets.flatten())\r\n",
        "                # back propagation\r\n",
        "                loss.backward()\r\n",
        "                self.optimizer.step() # update model weights\r\n",
        "                train_loss += loss.data.item()\r\n",
        "                if (idx % 10 == 0) and verbose:\r\n",
        "                    print(f\"epoch {epoch+1}/{n_epochs}, batch {idx}.\")\r\n",
        "            train_loss = train_loss / len(train_loader)\r\n",
        "            train_losses.append(train_loss)\r\n",
        "           \r\n",
        "            # Validation \r\n",
        "            self.network.eval()        \r\n",
        "            for batch in val_loader:\r\n",
        "                inputs, targets = batch\r\n",
        "                inputs, targets = [tensor.to(device) for tensor in batch]\r\n",
        "                targets = targets.long() # converts dtype to Long\r\n",
        "                output = self.network(inputs)\r\n",
        "                loss = self.loss_fn(output, targets.flatten())\r\n",
        "                val_loss += loss.data.item()\r\n",
        "\r\n",
        "            val_loss = val_loss / len(val_loader)\r\n",
        "            val_losses.append(val_loss)\r\n",
        "\r\n",
        "            if val_loss < best_val_loss:\r\n",
        "              best_params = self.network.parameters()\r\n",
        "              best_val_loss = val_loss\r\n",
        "              best_val_epoch = epoch\r\n",
        "            \r\n",
        "            # If validation loss fails to decrease for some number of epochs\r\n",
        "            # end training\r\n",
        "            if np.abs(epoch - best_val_epoch) > early_stopping_buffer:\r\n",
        "              break\r\n",
        "        \r\n",
        "            print(f\"Epoch: {epoch}, Training Loss: {train_loss:.3f}, \"\r\n",
        "                 +f\"Validation loss: {val_loss:.3f}\")\r\n",
        "        \r\n",
        "        #self.network.parameters = best_params\r\n",
        "        self.best_val_loss = best_val_loss\r\n",
        "        self.best_val_epoch = best_val_epoch\r\n",
        "        if plot:\r\n",
        "            skip_frames = 3\r\n",
        "            fig, ax = plt.subplots()\r\n",
        "            fig.tight_layout()\r\n",
        "            if plot_train:\r\n",
        "              ax.plot(np.arange(epoch + 1)[skip_frames:], \r\n",
        "                      train_losses[skip_frames:], '-', label=\"training set\")\r\n",
        "            ax.plot(np.arange(epoch + 1)[skip_frames:], \r\n",
        "                    val_losses[skip_frames:], '-', label=\"test set\")\r\n",
        "            ax.set(xlabel=\"Epoch\", ylabel=\"Loss\")\r\n",
        "            ax.legend()\r\n",
        "            plt.show() \r\n",
        "    \r\n",
        "    # ----------------------------------\r\n",
        "    # Data preparation hooks\r\n",
        "    # ----------------------------------\r\n",
        "    def prepare_data(self):\r\n",
        "        \"\"\"\r\n",
        "        Args:\r\n",
        "            X : feature matrix\r\n",
        "            Y : target matrix\r\n",
        "        X, Y = self.X, self.Y\r\n",
        "        global X_train, Y_train\r\n",
        "        global X_val, Y_val\r\n",
        "        global X_test, Y_test\r\n",
        "        splits = np.array([84, 15, 1]) / 100\r\n",
        "        train_size, val_size, test_size = splits\r\n",
        "        # train-test split\r\n",
        "        train_test_splits = model_selection.train_test_split(\r\n",
        "            X, Y, test_size = test_size, random_state = 42)\r\n",
        "        X_train, X_test, Y_train, Y_test = train_test_splits\r\n",
        "        # train-val split\r\n",
        "        relative_val_size = val_size / (train_size + val_size)\r\n",
        "        train_val_splits = model_selection.train_test_split(\r\n",
        "            X_train, Y_train, test_size = relative_val_size,\r\n",
        "            random_state = 42)\r\n",
        "        X_train, X_val, Y_train, Y_val = train_val_splits\r\n",
        "        assert X_train.shape[0] + X_val.shape[0] + X_test.shape[0] == X.shape[0] \r\n",
        "        \"\"\"\r\n",
        "        pass \r\n",
        "        \r\n",
        "    def setup(self, stage=None):\r\n",
        "        if stage in [\"fit\", None]:\r\n",
        "            self.train_set = train_set\r\n",
        "            self.val_set = val_set\r\n",
        "        if stage in [\"test\", None]:\r\n",
        "            self.test_set = test_set\r\n",
        "\r\n",
        "    def get_dataloader(self, stage: str):\r\n",
        "        if stage == \"train\":\r\n",
        "            dataset = self.train_set\r\n",
        "        if stage == \"val\":\r\n",
        "            dataset = self.val_set\r\n",
        "        if stage == \"test\":\r\n",
        "            dataset = self.test_set\r\n",
        "        dl = torch.utils.data.DataLoader(\r\n",
        "            dataset = dataset, batch_size = self.BATCH_SIZE) \r\n",
        "        return dl \r\n",
        "        \r\n",
        "    def train_dataloader(self) -> torch.utils.data.DataLoader:\r\n",
        "        return self.get_dataloader(\"train\")\r\n",
        "    def val_dataloader(self) -> torch.utils.data.DataLoader:\r\n",
        "        return self.get_dataloader(\"val\")\r\n",
        "    def test_dataloader(self) -> torch.utils.data.DataLoader:\r\n",
        "        return self.get_dataloader(\"test\")\r\n",
        "    \r\n",
        "    # ----------------------------------\r\n",
        "    # Helper functions - Use post-training\r\n",
        "    # ----------------------------------\r\n",
        "    \r\n",
        "    def predict(self, x: torch.Tensor) -> torch.Tensor:\r\n",
        "        self.eval()\r\n",
        "        x.to(self.device)\r\n",
        "        logits = self(x)\r\n",
        "        preds = torch.argmax(input = logits, dim=1)\r\n",
        "        return preds\r\n",
        "\r\n",
        "    def accuracy(self, pred: torch.Tensor, target: torch.Tensor):\r\n",
        "        self.eval()\r\n",
        "        if isinstance(pred, torch.Tensor) and isinstance(target, torch.Tensor):\r\n",
        "            pred, target = [t.to(self.device) for t in [pred, target]]\r\n",
        "        elif isinstance(pred, np.ndarray) and isinstance(target, np.ndarray):\r\n",
        "            tensors = [torch.Tensor(t).to(self.device) for t in [pred, target]]\r\n",
        "            pred, target = tensors\r\n",
        "        else:\r\n",
        "            raise ValueError(\"The types of `pred` and `target` must match. \"\r\n",
        "                + \"These can be np.ndarrays or torch.Tensors.\")\r\n",
        "\r\n",
        "        accuracy = pl.metrics.functional.accuracy(pred, target)\r\n",
        "        return accuracy\r\n",
        "\r\n",
        "    def f1(self, pred: torch.Tensor, target: torch.Tensor):\r\n",
        "        self.eval()\r\n",
        "        if isinstance(pred, torch.Tensor) and isinstance(target, torch.Tensor):\r\n",
        "            pred, target = [t.to(self.device) for t in [pred, target]]\r\n",
        "        elif isinstance(pred, np.ndarray) and isinstance(target, np.ndarray):\r\n",
        "            tensors = [torch.Tensor(t).to(self.device) for t in [pred, target]]\r\n",
        "            pred, target = tensors\r\n",
        "        else:\r\n",
        "            raise ValueError(\"The types of `pred` and `target` must match. \"\r\n",
        "                + \"These can be np.ndarrays or torch.Tensors.\")\r\n",
        "        f1 = pl.metrics.functional.f1(\r\n",
        "            preds = pred, target = target, num_classes = 3, multilabel = True)\r\n",
        "        return f1\r\n",
        "        \r\n",
        "    def multiclass_aucroc(self, pred: torch.Tensor, target: torch.Tensor):\r\n",
        "        self.eval()\r\n",
        "        if isinstance(pred, torch.Tensor) and isinstance(target, torch.Tensor):\r\n",
        "            pred, target = [t.to(self.device) for t in [pred, target]]\r\n",
        "        elif isinstance(pred, np.ndarray) and isinstance(target, np.ndarray):\r\n",
        "            tensors = [torch.Tensor(t).to(self.device) for t in [pred, target]]\r\n",
        "            pred, target = tensors\r\n",
        "        else:\r\n",
        "            raise ValueError(\"The types of `pred` and `target` must match. \"\r\n",
        "                + \"These can be np.ndarrays or torch.Tensors.\")\r\n",
        "        auc_roc = pl.metrics.functional.classification.multiclass_auroc(\r\n",
        "            pred = pred, target = target)\r\n",
        "        return auc_roc\r\n",
        "\r\n",
        "    def plot_losses(self, plot_train=True):\r\n",
        "        skip_frames = 1\r\n",
        "        fig, ax = plt.subplots()\r\n",
        "        fig.tight_layout()\r\n",
        "\r\n",
        "        n_epochs = len(self.epoch_val_losses)\r\n",
        "        self.epoch_train_losses = [s.pop() for s in self.epoch_train_losses]\r\n",
        "        self.epoch_val_losses = [s.pop() for s in self.epoch_val_losses]\r\n",
        "        if plot_train:\r\n",
        "            n_epochs = len(self.epoch_train_losses)\r\n",
        "            ax.plot(np.arange(n_epochs)[skip_frames:], \r\n",
        "                    self.epoch_train_losses[skip_frames:], label=\"train\")\r\n",
        "        ax.plot(np.arange(n_epochs)[skip_frames:], \r\n",
        "                self.epoch_val_losses[1:][skip_frames:], label=\"val\")\r\n",
        "        ax.set(xlabel=\"Epoch\", ylabel=\"Loss\")\r\n",
        "        ax.legend()\r\n",
        "        plt.show()\r\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0lwJ8AwqgMt3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf8cd759-b4d8-4f46-da5b-94c8bf45a4e1"
      },
      "source": [
        "try:\r\n",
        "    print(f\"X.shape: {X.shape},\\tY.shape: {Y.shape}\")\r\n",
        "except:\r\n",
        "    pp = preprocessing.Preprocessing()\r\n",
        "    Y, names = pp.get_Y(data_path=data_path)\r\n",
        "    X = pd.read_csv(os.path.join(data_path, \"X.csv\")).values\r\n",
        "    print(f\"X.shape: {X.shape},\\tY.shape: {Y.shape}\")"
      ],
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X.shape: (4061, 25869),\tY.shape: (4061, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XhqwU7Cw2cUS"
      },
      "source": [
        "# Specify training and testing sets\r\n",
        "try:\r\n",
        "    print([A.shape for A in [X_TRAIN, Y_TRAIN, X_TEST, Y_TEST]])\r\n",
        "except:\r\n",
        "    # train-test split\r\n",
        "    test_split = 0.15\r\n",
        "    TEST_IDX = np.array(random.sample(range(4061), k = round(test_split * 4061)))\r\n",
        "    TRAIN_IDX = np.array(list(set(np.arange(Y.size)).difference(set(TEST_IDX))))\r\n",
        "\r\n",
        "    X_TRAIN, Y_TRAIN = X[TRAIN_IDX], Y[TRAIN_IDX] \r\n",
        "    X_TEST, Y_TEST = X[TEST_IDX], Y[TEST_IDX]\r\n",
        "\r\n",
        "    TRAIN_SET = TabularDataset(X_TRAIN, Y_TRAIN)  \r\n",
        "    TEST_SET = TabularDataset(X_TEST, Y_TEST)\r\n",
        "    del X"
      ],
      "execution_count": 164,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OEkhFtZwlK2-"
      },
      "source": [
        "def X_selectk(k: int, tt_split = False) -> np.ndarray:\n",
        "    \"\"\"Grabs the X with the \"best\" k features and returns it. \n",
        "    If `tt_split` is true, the train and test splits are applied as well.\n",
        "    \"\"\"\n",
        "    chi2 = feature_selection.chi2\n",
        "    selectk = feature_selection.SelectKBest(chi2, k = k)\n",
        "    X = np.vstack([X_TRAIN, X_TEST])\n",
        "    Y = np.vstack([Y_TRAIN, Y_TEST])\n",
        "    X_r: np.ndarray = selectk.fit_transform(X, Y.flatten()).astype(float)\n",
        "\n",
        "    if tt_split:\n",
        "        return X_r[TRAIN_IDX], X_r[TEST_IDX]\n",
        "    else:\n",
        "        return X_r\n",
        "\n",
        "K_VALS = [int(k) for k in [10, 100, 500, 1e3, 5e3, 10e3, 25e3]]"
      ],
      "execution_count": 165,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHwnsvdxPCyC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e1c449b-e925-4688-d621-bc924dd7483d"
      },
      "source": [
        "X_selectk(K_VALS[0], False).shape"
      ],
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4061, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 174
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_ifKBbA9Hhw"
      },
      "source": [
        "def PCA_req_components(X: np.ndarray, threshold = 0.99, plot=True, verbose=False):\r\n",
        "    n_samples, n_features = X.shape[0], X.shape[1]\r\n",
        "    components = min({n_samples, n_features})\r\n",
        "    if n_features < components:\r\n",
        "        components = n_features\r\n",
        "    pca = decomposition.PCA(n_components = components)\r\n",
        "    pca.fit(X)\r\n",
        "    \r\n",
        "    cusum = np.cumsum(pca.explained_variance_ratio_)\r\n",
        "    threshold_line = np.ones(components) * threshold\r\n",
        "    p_components = np.arange(components) + 1\r\n",
        "    if plot:\r\n",
        "        fig, ax = plt.subplots(figsize=(8, 6))\r\n",
        "        ax.plot(p_components, cusum, label='cumulative variance explained')\r\n",
        "        ax.plot(p_components, threshold_line, '--', label='threshold')\r\n",
        "        # ax.plot(p_components, pca.explained_variance_ratio_, 'o', \r\n",
        "        #         label='individual variance explained')\r\n",
        "        ax.set(title = f\"Variance Explained, n_features = {n_features}\",\r\n",
        "               xlabel = \"Principal components\", \r\n",
        "               ylabel = \"Percentage of Variance Explained\")\r\n",
        "        ax.legend()\r\n",
        "        plt.show()\r\n",
        "\r\n",
        "    reduced_components = list(cusum >= threshold).index(True)\r\n",
        "    # Thresholds, required components table\r\n",
        "    thresholds = [0.9, 0.95, 0.97, 0.99, 0.999]\r\n",
        "    idx = []\r\n",
        "    for t in thresholds:\r\n",
        "        idx.append(list(cusum >= t).index(True))\r\n",
        "    thresholds, idx = [np.array(l) for l in [thresholds, idx]]\r\n",
        "    req_components = pd.DataFrame(np.vstack([thresholds, idx]),\r\n",
        "                                  index = [\"threshold\", \"principal components\"])\r\n",
        "    return req_components\r\n",
        "\r\n",
        "def PCA_reduction(X: np.ndarray, n: int) -> np.ndarray:\r\n",
        "    \"\"\" Transforms a feature matrix with PCA feature reduction.\r\n",
        "    Args:\r\n",
        "        X (np.ndarray): Feature matrix\r\n",
        "        n (int): number of principal axis components\r\n",
        "    Returns:\r\n",
        "        X_new (np.ndarray): X with PCA feature reduction.\r\n",
        "    \"\"\"\r\n",
        "    n_samples, n_features = X.shape[0], X.shape[1]\r\n",
        "    pca = decomposition.PCA(n_components = n)\r\n",
        "    X_new = pca.fit_transform(X)\r\n",
        "    return X_new"
      ],
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8NQrTf1Ir__"
      },
      "source": [
        "# for k in K_VALS:\r\n",
        "#     req_components = PCA_req_components(X_selectk(k, False), plot = True, \r\n",
        "#                                         verbose = True)\r\n",
        "#     print(f\"k: {k}\")\r\n",
        "#     print(req_components)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cxIdTg9Ldpu0"
      },
      "source": [
        "### Example outputs: \r\n",
        "\r\n",
        "The following results come from using the X in `data/X.csv` with methods defined above and running\r\n",
        "\r\n",
        "```python\r\n",
        "for k in K_VALS:\r\n",
        "    req_components = PCA_req_components(X_selectk(k, False), plot = True, \r\n",
        "                                        verbose = True)\r\n",
        "    print(f\"k: {k}\")\r\n",
        "    print(req_components)\r\n",
        "```\r\n",
        "\r\n",
        "![alt text][r10]\r\n",
        "\r\n",
        "```\r\n",
        "r: 10\r\n",
        "                        0     1     2     3      4\r\n",
        "threshold             0.9  0.95  0.97  0.99  0.999\r\n",
        "principal components  0.0  0.00  0.00  2.00  6.000\r\n",
        "```\r\n",
        "\r\n",
        "![alt text][r100]\r\n",
        "\r\n",
        "```\r\n",
        "r: 100\r\n",
        "threshold             0.9  0.95  0.97   0.99   0.999\r\n",
        "principal components  0.0  0.00  3.00  18.00  55.000\r\n",
        "```\r\n",
        "\r\n",
        "![alt text][r500]\r\n",
        "\r\n",
        "\r\n",
        "```\r\n",
        "r: 500\r\n",
        "threshold             0.9  0.95   0.97   0.99    0.999\r\n",
        "principal components  0.0  6.00  22.00  83.00  258.000\r\n",
        "```\r\n",
        "\r\n",
        "![alt text][r1k]\r\n",
        "\r\n",
        "```\r\n",
        "r: 1000\r\n",
        "threshold             0.9   0.95   0.97    0.99    0.999\r\n",
        "principal components  1.0  29.00  65.00  182.00  511.000\r\n",
        "```\r\n",
        "\r\n",
        "![alt text][r5k]\r\n",
        "\r\n",
        "```\r\n",
        "r: 5000\r\n",
        "threshold               0.9    0.95    0.97     0.99     0.999\r\n",
        "principal components  135.0  329.00  519.00  1024.00  2149.000\r\n",
        "```\r\n",
        "\r\n",
        "![alt text][r10k]\r\n",
        "\r\n",
        "```\r\n",
        "r: 10000\r\n",
        "threshold               0.9    0.95     0.97     0.99     0.999\r\n",
        "principal components  359.0  702.00  1008.00  1750.00  3112.000\r\n",
        "```\r\n",
        "\r\n",
        "![alt text][r25k]\r\n",
        "\r\n",
        "```\r\n",
        "r: 25000\r\n",
        "threshold               0.9     0.95     0.97     0.99     0.999\r\n",
        "principal components  903.0  1481.00  1934.00  2818.00  3809.000\r\n",
        "```\r\n",
        "\r\n",
        "[r10]: https://github.com/Unique-Divine/Neural-Networks-for-Genomic-Risk/raw/master/images/var_explained-r10.png \"\"\r\n",
        "\r\n",
        "[r100]: https://github.com/Unique-Divine/Neural-Networks-for-Genomic-Risk/raw/master/images/var_explained-r100.png \"\"\r\n",
        "\r\n",
        "[r500]: https://github.com/Unique-Divine/Neural-Networks-for-Genomic-Risk/raw/master/images/var_explained-r500.png \"\"\r\n",
        "\r\n",
        "[r1k]: https://github.com/Unique-Divine/Neural-Networks-for-Genomic-Risk/raw/master/images/var_explained-r1k.png \"\"\r\n",
        "\r\n",
        "[r5k]: https://github.com/Unique-Divine/Neural-Networks-for-Genomic-Risk/raw/master/images/var_explained-r5k.png \"\"\r\n",
        "\r\n",
        "[r10k]: https://github.com/Unique-Divine/Neural-Networks-for-Genomic-Risk/raw/master/images/var_explained-r10k.png \"\"\r\n",
        "\r\n",
        "[r25k]: https://github.com/Unique-Divine/Neural-Networks-for-Genomic-Risk/raw/master/images/var_explained-r25k.png \"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JoW3efWUjV--"
      },
      "source": [
        "---\r\n",
        "\r\n",
        "# Data set balance analysis\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F87N39ggj4Za"
      },
      "source": [
        ""
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "zNAi6qaZjbRT",
        "outputId": "f020ceb9-ad95-4709-8838-604ea4824700"
      },
      "source": [
        "np.set_printoptions(precision = 3)\r\n",
        "def balance_check(Y: np.ndarray = Y, verbose=False, plot=False):\r\n",
        "    y = pd.Series(Y.flatten(), dtype=int)\r\n",
        "    counts = np.array([c for c in [y.value_counts()]]).flatten()\r\n",
        "    pcts = counts / counts.sum() * 100\r\n",
        "    labels = y.unique()\r\n",
        "    if verbose:\r\n",
        "        print(\"counts: {}\\npcts: {}\\nlabels: {}\".format(\r\n",
        "        counts, pcts, labels))\r\n",
        "    if plot:\r\n",
        "        fig, ax = plt.subplots(figsize = (8, 6))\r\n",
        "        ax.bar(labels, pcts, width=0.2);\r\n",
        "        sweetspot = 1 / labels.size * 100\r\n",
        "        sweetspot_line = np.ones(50) * sweetspot\r\n",
        "        ax.plot(np.linspace(labels[0], labels[-1]), sweetspot_line, 'r--')\r\n",
        "        ax.set(xlabel = \"Label\", ylabel = \"percentage\", title=\"Dataset Balance\")\r\n",
        "        ax.grid()\r\n",
        "        plt.show()\r\n",
        "    class DatasetBalance(dict):\r\n",
        "        def __init__(self, counts, pcts, labels):\r\n",
        "            dictionary = {'counts': counts, 'pcts': pcts, 'labels': labels}\r\n",
        "            self.counts = counts\r\n",
        "            self.pcts = pcts\r\n",
        "            self.labels = labels\r\n",
        "            self.update(dictionary)\r\n",
        "    balance = DatasetBalance(counts, pcts, labels)\r\n",
        "    return balance\r\n",
        "\r\n",
        "balance_check(Y, verbose = True, plot=True);"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "counts: [1575 1372 1114]\n",
            "pcts: [38.784 33.785 27.432]\n",
            "labels: [0 1 2]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QR4yM0IStpx4"
      },
      "source": [
        "toy_X = PCA_reduction(X_r(10), n = 6)"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a3Hz_lxNt7ZO",
        "outputId": "212a25af-b252-459e-dc42-9c8e2802aadb"
      },
      "source": [
        "def play():\r\n",
        "    toy_X.shape, Y.shape\r\n",
        "    balance = balance_check()\r\n",
        "    \r\n",
        "    # get sets of the indices where Y is a certain label\r\n",
        "    indices: List[np.ndarray] = []\r\n",
        "    for i in balance.labels:\r\n",
        "        idx: np.ndarray = np.array((Y == i).flatten().nonzero()[0])\r\n",
        "        indices.append(idx)\r\n",
        "    \r\n",
        "    # randomly select elements of idx in `indices` wihout repetition\r\n",
        "    equal_count = balance.counts.min()\r\n",
        "    # game = random.sample(population = , k = equal_count)\r\n",
        "\r\n",
        "    return game\r\n",
        "play()"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1114"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ewF_40oc1NtS"
      },
      "source": [
        "random.sample?"
      ],
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08LYuvqDOyS_"
      },
      "source": [
        "---\n",
        "\n",
        "# Evaluating GAN reasonable GAN parameters\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kEDkhFjMOjiG"
      },
      "source": [
        "REAL_DATA = X_new"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jNE4OqAIvPZz",
        "outputId": "32194cc7-9df8-4fab-9a60-5d0791c045b6"
      },
      "source": [
        "start_time = time.time()\r\n",
        "g = gans.TabularGANs(\r\n",
        "        X = REAL_DATA, Y = Y, \r\n",
        "        gen_dim = (100, 100),\r\n",
        "        dis_dim = (10, 10),\r\n",
        "        embedding_dim = 1000,\r\n",
        "        epochs = 2, \r\n",
        "        l2scale = 1e-4,\r\n",
        "        batch_size = 500)\r\n",
        "g.train_GANs()\r\n",
        "current_time = time.time() - start_time\r\n",
        "print(f\"training took {current_time:.1f}s\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training took 4.1s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Jj7X3h2xASu",
        "outputId": "ca77a9b3-03c6-48a0-e078-4e417dc4098e"
      },
      "source": [
        "def eval_test(real_x, real_y, generator_model: gans.TabularGANs) -> float:\r\n",
        "    \"\"\"\r\n",
        "    \"\"\"\r\n",
        "    # prepare real data\r\n",
        "    real_y = real_y.reshape(-1, 1)\r\n",
        "    real_data = np.hstack([real_x, real_y]).astype(float)\r\n",
        "    # prepare synth data\r\n",
        "    sx, sy = g.create_synth_samples(REAL_DATA.shape[0])\r\n",
        "    sy = sy.reshape(-1, 1)\r\n",
        "    s = np.hstack([sx, sy]).astype(float)\r\n",
        "    # evaluate\r\n",
        "    eval: dict = g.evaluate_synth_data(\r\n",
        "        synth_data = pd.DataFrame(s), \r\n",
        "        real_data = pd.DataFrame(real_data), \r\n",
        "        aggregate = False)\r\n",
        "    eval: float = list(eval.values())[0]\r\n",
        "    return eval\r\n",
        "eval_test(REAL_DATA, Y, g)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.623211599768234"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 149
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2lKGzljBhBg6"
      },
      "source": [
        "GAN_TESTS = {}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fgWbyVkeP7D8"
      },
      "source": [
        "def gan_parameter_test(real_x, real_y, generator_model: gans.TabularGANs, tests=5):\r\n",
        "    original_model = generator_model\r\n",
        "    parameters = generator_model.params\r\n",
        "    evaluations = np.empty(tests)\r\n",
        "    for test in range(tests):\r\n",
        "        start_time = time.time()\r\n",
        "        test_model = original_model\r\n",
        "        test_model.train_GANs()\r\n",
        "        current_time = time.time() - start_time\r\n",
        "        eta = current_time * (tests - test) \r\n",
        "        print(f\"Training step speed {current_time:.1f} s\"\r\n",
        "            + f\"\\tETA: {eta:.1f} s\")\r\n",
        "\r\n",
        "        evaluation = eval_test(real_x, real_y, generator_model)\r\n",
        "        evaluations[test] = evaluation\r\n",
        "    score = evaluations.mean()\r\n",
        "    GAN_TESTS[score] = parameters"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qavsPIamUx5G"
      },
      "source": [
        "g = gans.TabularGANs(\r\n",
        "    X = REAL_DATA, Y = Y, \r\n",
        "    gen_dim = (20, 20),\r\n",
        "    dis_dim = (50, 50),\r\n",
        "    embedding_dim = 100,\r\n",
        "    epochs = 75, \r\n",
        "    l2scale = 1e-4,\r\n",
        "    batch_size = 500)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f5yQG4HJHusJ",
        "outputId": "b8a0014b-583c-4d29-da90-5cfc13b26ce2"
      },
      "source": [
        "gan_parameter_test(REAL_DATA, Y, g)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training step speed 16.4 s\tETA: 81.9 s\n",
            "Training step speed 14.2 s\tETA: 56.9 s\n",
            "Training step speed 14.1 s\tETA: 42.2 s\n",
            "Training step speed 14.4 s\tETA: 28.9 s\n",
            "Training step speed 14.2 s\tETA: 14.2 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2DyENXD9cHdX"
      },
      "source": [
        "def save_gan_tests(overwrite = False):\r\n",
        "    if os.path.exists(os.path.join(data_path, \"gan_params.p\")) == False:\r\n",
        "        with open(os.path.join(data_path, \"gan_params.p\"), 'wb') as fp:\r\n",
        "            pickle.dump(GAN_TESTS, fp, protocol=pickle.HIGHEST_PROTOCOL)\r\n",
        "        print(\"Parameters saved.\")\r\n",
        "    if overwrite:\r\n",
        "        with open(os.path.join(data_path, \"gan_params.p\"), 'wb') as fp:\r\n",
        "            pickle.dump(GAN_TESTS, fp, protocol=pickle.HIGHEST_PROTOCOL)\r\n",
        "    else:\r\n",
        "        print(\"The parameters were already saved previously.\" \r\n",
        "            + \"To overwrite the save, set `overwrite = True`.\")\r\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_DzphjZNcfUv",
        "outputId": "c48dc6d5-eabf-4ee1-94db-1ae771298d20"
      },
      "source": [
        "def load_gan_tests() -> dict:\r\n",
        "    with open(os.path.join(data_path, \"gan_params.p\"), 'rb') as fp:\r\n",
        "        gan_params: dict = pickle.load(fp)\r\n",
        "    return gan_params\r\n",
        "load_gan_tests()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0.5674040020528077: {'batch_size': 500,\n",
              "  'dis_dim': (50, 50),\n",
              "  'embedding_dim': 100,\n",
              "  'epochs': 75,\n",
              "  'gen_dim': (20, 20),\n",
              "  'l2scale': 0.0001},\n",
              " 0.5685682816354259: {'batch_size': 500,\n",
              "  'dis_dim': (50, 50),\n",
              "  'embedding_dim': 100,\n",
              "  'epochs': 50,\n",
              "  'gen_dim': (20, 20),\n",
              "  'l2scale': 0.0001},\n",
              " 0.5749121749272297: {'batch_size': 500,\n",
              "  'dis_dim': (50, 50),\n",
              "  'embedding_dim': 100,\n",
              "  'epochs': 5,\n",
              "  'gen_dim': (5, 5),\n",
              "  'l2scale': 0.0001},\n",
              " 0.576530821340115: {'batch_size': 500,\n",
              "  'dis_dim': (50, 50),\n",
              "  'embedding_dim': 100,\n",
              "  'epochs': 100,\n",
              "  'gen_dim': (20, 20),\n",
              "  'l2scale': 0.0001},\n",
              " 0.5785666217070802: {'batch_size': 500,\n",
              "  'dis_dim': (50, 50),\n",
              "  'embedding_dim': 100,\n",
              "  'epochs': 25,\n",
              "  'gen_dim': (20, 20),\n",
              "  'l2scale': 0.0001},\n",
              " 0.5865022262111977: {'batch_size': 500,\n",
              "  'dis_dim': (50, 50),\n",
              "  'embedding_dim': 100,\n",
              "  'epochs': 10,\n",
              "  'gen_dim': (20, 20),\n",
              "  'l2scale': 0.0001},\n",
              " 0.5870081627287909: {'batch_size': 500,\n",
              "  'dis_dim': (50, 50),\n",
              "  'embedding_dim': 100,\n",
              "  'epochs': 5,\n",
              "  'gen_dim': (20, 20),\n",
              "  'l2scale': 0.0001},\n",
              " 0.5877103068395282: {'batch_size': 500,\n",
              "  'dis_dim': (50, 50),\n",
              "  'embedding_dim': 100,\n",
              "  'epochs': 5,\n",
              "  'gen_dim': (10, 10),\n",
              "  'l2scale': 0.0001},\n",
              " 0.5989898807675941: {'batch_size': 500,\n",
              "  'dis_dim': (50, 50),\n",
              "  'embedding_dim': 100,\n",
              "  'epochs': 5,\n",
              "  'gen_dim': (50, 50),\n",
              "  'l2scale': 0.0001},\n",
              " 0.6026186747617391: {'batch_size': 500,\n",
              "  'dis_dim': (5, 5),\n",
              "  'embedding_dim': 100,\n",
              "  'epochs': 5,\n",
              "  'gen_dim': (20, 20),\n",
              "  'l2scale': 0.0001},\n",
              " 0.6047613809301506: {'batch_size': 500,\n",
              "  'dis_dim': (50, 50),\n",
              "  'embedding_dim': 800,\n",
              "  'epochs': 5,\n",
              "  'gen_dim': (20, 20),\n",
              "  'l2scale': 0.0001},\n",
              " 0.6072181078327212: {'batch_size': 500,\n",
              "  'dis_dim': (5, 5),\n",
              "  'embedding_dim': 100,\n",
              "  'epochs': 5,\n",
              "  'gen_dim': (5, 5),\n",
              "  'l2scale': 0.0001},\n",
              " 0.6077451991831262: {'batch_size': 500,\n",
              "  'dis_dim': (50, 50),\n",
              "  'embedding_dim': 100,\n",
              "  'epochs': 10,\n",
              "  'gen_dim': (5, 5),\n",
              "  'l2scale': 0.0001},\n",
              " 0.6107637472679167: {'batch_size': 500,\n",
              "  'dis_dim': (50, 50),\n",
              "  'embedding_dim': 50,\n",
              "  'epochs': 5,\n",
              "  'gen_dim': (50, 50),\n",
              "  'l2scale': 0.0001},\n",
              " 0.6113756274600075: {'batch_size': 500,\n",
              "  'dis_dim': (50, 50),\n",
              "  'embedding_dim': 300,\n",
              "  'epochs': 5,\n",
              "  'gen_dim': (20, 20),\n",
              "  'l2scale': 0.0001},\n",
              " 0.6159734824740083: {'batch_size': 500,\n",
              "  'dis_dim': (50, 50),\n",
              "  'embedding_dim': 150,\n",
              "  'epochs': 5,\n",
              "  'gen_dim': (20, 20),\n",
              "  'l2scale': 0.0001},\n",
              " 0.6218641415404881: {'batch_size': 500,\n",
              "  'dis_dim': (50, 50),\n",
              "  'embedding_dim': 2000,\n",
              "  'epochs': 2,\n",
              "  'gen_dim': (50, 50),\n",
              "  'l2scale': 0.0001},\n",
              " 0.6340404356579844: {'batch_size': 500,\n",
              "  'dis_dim': (20, 20),\n",
              "  'embedding_dim': 100,\n",
              "  'epochs': 5,\n",
              "  'gen_dim': (20, 20),\n",
              "  'l2scale': 0.0001},\n",
              " 0.6378401806200024: {'batch_size': 500,\n",
              "  'dis_dim': (20, 20),\n",
              "  'embedding_dim': 100,\n",
              "  'epochs': 5,\n",
              "  'gen_dim': (20, 20),\n",
              "  'l2scale': 0.0001},\n",
              " 0.647099619665503: {'batch_size': 500,\n",
              "  'dis_dim': (50, 50),\n",
              "  'embedding_dim': 100,\n",
              "  'epochs': 2,\n",
              "  'gen_dim': (50, 50),\n",
              "  'l2scale': 0.0001},\n",
              " 0.6471713985608973: {'batch_size': 500,\n",
              "  'dis_dim': (50, 50),\n",
              "  'embedding_dim': 500,\n",
              "  'epochs': 2,\n",
              "  'gen_dim': (50, 50),\n",
              "  'l2scale': 0.0001},\n",
              " 0.6547640939840887: {'batch_size': 500,\n",
              "  'dis_dim': (50, 50),\n",
              "  'embedding_dim': 50,\n",
              "  'epochs': 2,\n",
              "  'gen_dim': (50, 50),\n",
              "  'l2scale': 0.0001},\n",
              " 0.6612323123913957: {'batch_size': 500,\n",
              "  'dis_dim': (100, 100),\n",
              "  'embedding_dim': 1000,\n",
              "  'epochs': 2,\n",
              "  'gen_dim': (50, 50),\n",
              "  'l2scale': 0.0001},\n",
              " 0.6645767740594659: {'batch_size': 500,\n",
              "  'dis_dim': (50, 50),\n",
              "  'embedding_dim': 1000,\n",
              "  'epochs': 2,\n",
              "  'gen_dim': (50, 50),\n",
              "  'l2scale': 0.0001},\n",
              " 0.6647243471002036: {'batch_size': 500,\n",
              "  'dis_dim': (50, 50),\n",
              "  'embedding_dim': 1000,\n",
              "  'epochs': 2,\n",
              "  'gen_dim': (100, 100),\n",
              "  'l2scale': 0.0001}}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 255
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mqM12yfhV9-J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e32e930-821e-4ec5-f883-f3333ac86914"
      },
      "source": [
        "try:\n",
        "    print(gan_model.GANs, \"\\nGANs are already trained.\")\n",
        "except: \n",
        "    gan_model = gans.TabularGANs(\n",
        "        X = REAL_DATA, Y = Y, \n",
        "        epochs = 100)\n",
        "    print(\"training GANs...\")\n",
        "    gan_model.train_GANs()\n",
        "    print(f\"GANs trained.\\n{ml.GANs}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training GANs...\n",
            "GANs trained.\n",
            "<ctgan.synthesizer.CTGANSynthesizer object at 0x7f140a95c5c0>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDu0qmCUqR_4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "outputId": "5899636f-5d2c-46ac-b6a6-2f3c0435713b"
      },
      "source": [
        "X_fake, Y_fake = ml.getFakeSamples(n = 1000)\r\n",
        "print(X_fake.shape)\r\n",
        "Y_fake = np.around(Y_fake).astype(int)\r\n",
        "scaler = sklearn.preprocessing.MinMaxScaler()\r\n",
        "X_fake = scaler.fit_transform(X_fake)\r\n",
        "print(np.array([arr.shape for arr in [X_fake, Y_fake]]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-ec794ed01a4f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_fake\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_fake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetFakeSamples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_fake\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mY_fake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_fake\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mscaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMinMaxScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mX_fake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_fake\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'ml' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BBGdG_xFtzpx"
      },
      "source": [
        "---\n",
        "\n",
        "# Predictive Modeling\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 763
        },
        "id": "hNFybaCXsiju",
        "outputId": "f11b10d9-3a26-409c-d153-1736010bb234"
      },
      "source": [
        "network = LitFFNN(X = X_fake, Y = Y_fake, data_dir=data_path)\r\n",
        "trainer = pl.Trainer(max_epochs = 4, gpus = 0, fast_dev_run = True, \r\n",
        "    progress_bar_refresh_rate = 50)\r\n",
        "trainer.fit(network)\r\n",
        "network.plot_losses(plot_train = True)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-16-b7c1faecba81>\", line 1, in <module>\n",
            "    network = LitFFNN(X = X_fake, Y = Y_fake, data_dir=data_path)\n",
            "NameError: name 'X_fake' is not defined\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 1823, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'NameError' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 1132, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 313, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 358, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "  File \"/usr/lib/python3.6/inspect.py\", line 1490, in getinnerframes\n",
            "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
            "  File \"/usr/lib/python3.6/inspect.py\", line 1448, in getframeinfo\n",
            "    filename = getsourcefile(frame) or getfile(frame)\n",
            "  File \"/usr/lib/python3.6/inspect.py\", line 696, in getsourcefile\n",
            "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
            "  File \"/usr/lib/python3.6/inspect.py\", line 742, in getmodule\n",
            "    os.path.realpath(f)] = module.__name__\n",
            "  File \"/usr/lib/python3.6/posixpath.py\", line 395, in realpath\n",
            "    path, ok = _joinrealpath(filename[:0], filename, {})\n",
            "  File \"/usr/lib/python3.6/posixpath.py\", line 429, in _joinrealpath\n",
            "    if not islink(newpath):\n",
            "  File \"/usr/lib/python3.6/posixpath.py\", line 171, in islink\n",
            "    st = os.lstat(path)\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8AA3OUIJH6Mp",
        "outputId": "446ac6c0-4331-4a77-ccb1-fd289c1345c8"
      },
      "source": [
        "pred = network.predict(torch.Tensor(X_r))\r\n",
        "network.accuracy(pred, torch.Tensor(Y))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.3755)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wK_P_ZvqxQ7w"
      },
      "source": [
        "def test_training_method(verbose = False):\r\n",
        "    print(\"Testing training method: \")\r\n",
        "    network = LitFFNN(X = X_fake, Y = Y_fake, data_dir=data_path)\r\n",
        "    trainer = pl.Trainer(max_epochs = 4, gpus = 0, fast_dev_run=True, \r\n",
        "                         progress_bar_refresh_rate = 0)\r\n",
        "    trainer.fit(network)\r\n",
        "    if verbose:\r\n",
        "        print(network)\r\n",
        "    print(\"Test passed!\\n\")\r\n",
        "\r\n",
        "def test_output_consistency():\r\n",
        "    print(\"Testing model output consistency:\")\r\n",
        "    network = LitFFNN(X_r, Y)\r\n",
        "    preds = []\r\n",
        "    for i in range(2):\r\n",
        "        pred = network.predict(torch.Tensor(X_r))\r\n",
        "        preds.append(pred)\r\n",
        "\r\n",
        "    overlap = np.array((preds[0] == preds[1]))\r\n",
        "    t = overlap.sum() \r\n",
        "    f = overlap.size - t\r\n",
        "    t, f = np.array([t, f]) / (t  + f) \r\n",
        "    print(f\"Matched: {t:.2f} %,\\tMismatched: {f:.2f} %.\\n\")\r\n",
        "\r\n",
        "test_output_consistency()\r\n",
        "test_training_method()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NAWDYcter-6i"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ThYb04f-620M"
      },
      "source": [
        "\r\n",
        "# Train and evaluate neural network\r\n",
        "\r\n",
        "# Train and evaluate linear SVC\r\n",
        "\r\n",
        "# Train and evaluate XGB Classifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WiwqJdnKTwwh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QcdXgoOZL01L"
      },
      "source": [
        "```python\r\n",
        "# ckpt\r\n",
        "import logging\r\n",
        "import torch.multiprocessing as mp\r\n",
        "from torch.multiprocessing import Manager\r\n",
        "from tqdm import tqdm\r\n",
        "import time\r\n",
        "#mp.set_start_method('spawn')# good solution !!!!\r\n",
        "\r\n",
        "logging.getLogger('lightning').setLevel(0)\r\n",
        "\r\n",
        "early_stop_callback = EarlyStopping(\r\n",
        "   monitor='val_acc',\r\n",
        "   min_delta=0.00,\r\n",
        "   patience=5,\r\n",
        "   verbose=False,\r\n",
        "   mode='max'\r\n",
        ")\r\n",
        "\r\n",
        "\r\n",
        "def train_model(accuracies, rank):\r\n",
        "  start_time = time.time()\r\n",
        "  print('rank: ', rank)\r\n",
        "  A, indices = sample_from_data(100)\r\n",
        "  model = LitFFNN(X = A, Y = Y, \r\n",
        "      data_dir = os.path.join(data_path, \"temp\"))\r\n",
        "  trainer = pl.Trainer(gpus = 0, max_epochs=10, \r\n",
        "      progress_bar_refresh_rate=50, weights_summary=None,\r\n",
        "      callbacks=[early_stop_callback], num_sanity_val_steps=0)\r\n",
        "  trainer.fit(model)\r\n",
        "  acc = model.accuracy(\r\n",
        "    y_hat = model.predict(torch.Tensor(A.astype(float))),\r\n",
        "    y = torch.Tensor(Y.astype(float))).item()\r\n",
        "  accuracies.append(acc)\r\n",
        "\r\n",
        "with Manager() as manager:\r\n",
        "  accuracies = manager.list()  # <-- can be shared between processes.\r\n",
        "  indices = manager.list()  # <-- can be shared between processes.\r\n",
        "  processes = []\r\n",
        "  num_processes = 10\r\n",
        "  for i in tqdm(range(1)):\r\n",
        "    for rank in range(num_processes):\r\n",
        "      p = mp.Process(target=train_model, args=(accuracies, rank,))\r\n",
        "      p.start()\r\n",
        "      processes.append(p)\r\n",
        "    for p in processes:\r\n",
        "      p.join()\r\n",
        "  accuracies = list(accuracies)\r\n",
        "  ```"
      ]
    }
  ]
}