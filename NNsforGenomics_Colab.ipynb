{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NNsforGenomics_Colab.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bkh0Z3vEJuj1"
      },
      "source": [
        "For faster development speed, type `Ctrl + M, H` to view Google Colab keyboard shortcuts."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BiOsYGGAGd5C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "288c606a-2e3c-4b2e-ab26-9215b5d22ef2"
      },
      "source": [
        "!pip install pytorch-lightning --quiet\r\n",
        "# !curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\r\n",
        "# !python pytorch-xla-env-setup.py --version nightly --apt-packages libomp5 libopenblas-dev\r\n",
        "!pip install sdv --quiet"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 675kB 8.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 276kB 34.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 829kB 29.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 102kB 9.9MB/s \n",
            "\u001b[?25h  Building wheel for PyYAML (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 71kB 4.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 51kB 5.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 12.4MB 322kB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1MB 44.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 225kB 47.9MB/s \n",
            "\u001b[?25h  Building wheel for xeger (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for exrex (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: rdt 0.2.10 has requirement pandas<1.1.5,>=1.1, but you'll have pandas 1.1.5 which is incompatible.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rwgUdFx9ZQIl"
      },
      "source": [
        "### Getting Started\n",
        "\n",
        "\n",
        "#### Mounting your Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ze4LOQG2ZoAk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ee03bfb-f21e-42e1-81de-31a20f344f60"
      },
      "source": [
        "# np-pd-mpl\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns; sns.set()\n",
        "from numpy.lib.ufunclike import _deprecate_out_named_y\n",
        "\n",
        "# Neural network packages\n",
        "import torch\n",
        "import torch.nn as nn \n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data\n",
        "import torch.optim\n",
        "import pytorch_lightning as pl \n",
        "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
        "\n",
        "# Built-in\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "import copy\n",
        "import random\n",
        "import pickle\n",
        "from typing import List, Tuple, Dict, Any\n",
        "import logging\n",
        "logging.getLogger('lightning').setLevel(0)\n",
        "\n",
        "# sklearn\n",
        "from sklearn import feature_selection\n",
        "import sklearn.preprocessing\n",
        "import sklearn.metrics\n",
        "from sklearn import model_selection\n",
        "from sklearn import decomposition"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tIhoc7R7HhuB"
      },
      "source": [
        "Running the following cell will generate a message asking you to click on a link where you'll obtain an authorization code.\r\n",
        "\r\n",
        "Paste that authorization code into the text box that appears below to access Google Drive from this notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5908d_KoaoH3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17928314-0629-41d0-9c38-16c3c9c97213"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X8J16t4dZpOp",
        "outputId": "106d6aff-47c0-4b1f-db94-3de948ba10f2"
      },
      "source": [
        "!cd \"/content/gdrive/MyDrive/\" && ls # Displays directories in MyDrive/"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " ApTSi\t\t    Education\t'School-Related Planning'   地位を申し込む\n",
            "'Colab Notebooks'   Other\t SCIP\n",
            " Data\t\t    Recordings\t temp\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zJ2O5DloaWc0",
        "outputId": "12ba7b73-b0b8-45d2-c831-623a7f54ddba"
      },
      "source": [
        "dir_path = os.path.join(\"/content/gdrive/MyDrive/Data\", \"NNsforGenomics\")\r\n",
        "os.path.exists(dir_path)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dqxOD3I5RLdi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72c8bb8a-f987-4e62-8b0d-4b6f045f38d9"
      },
      "source": [
        "!cd {dir_path} && ls"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ctgan  data  gans.py  neural_networks.py  preprocessing.py  __pycache__\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JhpAy83kdexm"
      },
      "source": [
        "import sys\r\n",
        "sys.path.append(dir_path)\r\n",
        "data_path = os.path.join(dir_path, \"data\")\r\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "35-fUvYtgGz9"
      },
      "source": [
        "import ctgan \n",
        "import preprocessing\n",
        "import gans"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ofTQcvraH8y5"
      },
      "source": [
        "class TabularDataset(torch.utils.data.Dataset): # inherit from torch\r\n",
        "    def __init__(self, X: np.ndarray, Y: np.ndarray):\r\n",
        "        X, Y = [arr.astype(float) for arr in [X, Y]]\r\n",
        "        self.X = torch.from_numpy(X)\r\n",
        "        self.Y = torch.from_numpy(Y.reshape(-1,1))\r\n",
        "\r\n",
        "        self.n_samples = X.shape[0]\r\n",
        "        if self.X.shape[0] != self.Y.shape[0]:\r\n",
        "            raise ValueError(\"Shape mismatch. X and Y should have the same \" \r\n",
        "                + \"number of rows\")\r\n",
        "\r\n",
        "    def __getitem__(self, idx):\r\n",
        "        return self.X[idx], self.Y[idx]\r\n",
        "    \r\n",
        "    def __len__(self):\r\n",
        "        return self.n_samples"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8N9wcDxiH1qu"
      },
      "source": [
        "class LitFFNN(pl.LightningModule):\r\n",
        "    # ----------------------------------\r\n",
        "    # Initialize constants and NN architecture\r\n",
        "    # ----------------------------------\r\n",
        "    def __init__(self, X: np.ndarray, Y: np.ndarray, \r\n",
        "                 data_dir: str = data_path, batch_size = 50):\r\n",
        "        \"\"\" Feed-Forward Neural Network System\r\n",
        "        Args:\r\n",
        "            X (np.ndarray): Feature matrix \r\n",
        "            Y (np.ndarray): Target matrix\r\n",
        "        \"\"\"\r\n",
        "        super().__init__()\r\n",
        "        # TODO: train-val-test splits\r\n",
        "        self.X, self.Y = X, Y\r\n",
        "        self.n_features = self.X.shape[1]\r\n",
        "\r\n",
        "        # Hard-coded constants\r\n",
        "        self.loss_fn = nn.NLLLoss()\r\n",
        "        self.BATCH_SIZE = batch_size\r\n",
        "        self.lr = 1e-2\r\n",
        "        self.N_CLASSES = 3\r\n",
        "        \r\n",
        "        self.epoch = 0\r\n",
        "        self.prog_bar = True\r\n",
        "        # ----------------------------------\r\n",
        "        # Architecture\r\n",
        "        # ----------------------------------\r\n",
        "        self.D_IN = self.X.shape[1]\r\n",
        "        # D_h_in = int((2/3) * self.D_IN)\r\n",
        "        # D_h_out = int((1/3) * self.D_IN) \r\n",
        "        hidden_dim = int(np.sqrt(self.D_IN * self.N_CLASSES))\r\n",
        "        D_h_in = hidden_dim\r\n",
        "        D_h_out = hidden_dim\r\n",
        "\r\n",
        "        self.fc_layers = nn.Sequential(\r\n",
        "            nn.Linear(self.D_IN, D_h_in),\r\n",
        "                nn.LeakyReLU(),\r\n",
        "                nn.Dropout(p = 0.1),\r\n",
        "            nn.Linear(D_h_in, D_h_out),\r\n",
        "                nn.LeakyReLU(),\r\n",
        "                nn.Dropout(p = 0.2),\r\n",
        "            nn.Linear(D_h_out, self.N_CLASSES)\r\n",
        "        )\r\n",
        "\r\n",
        "        self.epoch_train_losses = []\r\n",
        "        self.epoch_val_losses = []\r\n",
        "        self.best_val_epoch = 0\r\n",
        "\r\n",
        "    def forward(self, x): \r\n",
        "        x = x.float()\r\n",
        "        x = self.fc_layers(x)\r\n",
        "        logits = F.log_softmax(input = x, dim = 1)\r\n",
        "        return logits\r\n",
        "\r\n",
        "    def configure_optimizers(self):\r\n",
        "        optimizer = torch.optim.Adam(\r\n",
        "            params = self.parameters(), lr = self.lr)\r\n",
        "        return optimizer\r\n",
        "\r\n",
        "    # ----------------------------------\r\n",
        "    # Training, validation, and test steps\r\n",
        "    # ----------------------------------\r\n",
        "\r\n",
        "    def training_step(self, batch, batch_idx):\r\n",
        "        x, y = batch\r\n",
        "        y = y.flatten().long()\r\n",
        "        logits = self(x) \r\n",
        "        loss = self.loss_fn(logits, y)\r\n",
        "        self.log('train_loss', loss, on_step=True, on_epoch=True, \r\n",
        "                 prog_bar=self.prog_bar)\r\n",
        "        return loss\r\n",
        "\r\n",
        "    def validation_step(self, batch, batch_idx, val=True):\r\n",
        "        x, y = batch\r\n",
        "        y = y.flatten().long()\r\n",
        "        # compute loss\r\n",
        "        logits = self(x)\r\n",
        "        loss = self.loss_fn(logits, y)\r\n",
        "        self.log('val_loss', loss, on_step=True, on_epoch=True, \r\n",
        "                 prog_bar=self.prog_bar) # self.log interacts with TensorBoard\r\n",
        "        return loss\r\n",
        "\r\n",
        "    def test_step(self, batch, batch_idx):\r\n",
        "        return self.validation_step(batch, batch_idx, val = False)\r\n",
        "\r\n",
        "    def training_epoch_end(self, outputs: List[Any]):\r\n",
        "        outputs: List[torch.Tensor] = [list(d.values())[0] for d in outputs]\r\n",
        "        sum = torch.zeros(1, dtype=float).to(self.device)\r\n",
        "        for batch_idx, batch_loss in enumerate(outputs):\r\n",
        "            sum += batch_loss.to(self.device)\r\n",
        "        avg_batch_loss = (sum / batch_idx)\r\n",
        "        self.epoch_train_losses.append({avg_batch_loss[0].item()})\r\n",
        "\r\n",
        "    def validation_epoch_end(self, outputs: List[Any]):\r\n",
        "        sum = torch.zeros(1, dtype=float).to(self.device)\r\n",
        "        for batch_idx, batch_loss in enumerate(outputs):\r\n",
        "            sum += batch_loss.to(self.device)\r\n",
        "        avg_batch_loss = (sum / batch_idx) \r\n",
        "        self.epoch_val_losses.append({avg_batch_loss[0].item()})        \r\n",
        "\r\n",
        "    def custom_train(self, n_epochs, plot=True, verbose=False, plot_train=False):\r\n",
        "        train_loader = self.train_dl\r\n",
        "        val_loader = self.test_dl\r\n",
        "        device=self.device\r\n",
        "        self.network.to(device)\r\n",
        "\r\n",
        "        train_losses, val_losses = [], []\r\n",
        "        best_val_loss = np.infty\r\n",
        "        best_val_epoch = 0\r\n",
        "        early_stopping_buffer = 10\r\n",
        "        epoch = 0\r\n",
        "        best_params = None\r\n",
        "        for epoch in range(n_epochs):\r\n",
        "            train_loss, val_loss = 0.0, 0.0\r\n",
        "  \r\n",
        "            # Training\r\n",
        "            self.network.train()\r\n",
        "            for idx, batch in enumerate(train_loader):\r\n",
        "                self.optimizer.zero_grad() # clears paramter gradient buffers\r\n",
        "                inputs, targets = batch\r\n",
        "                # transfer batch data to computation device\r\n",
        "                inputs, targets = [\r\n",
        "                    tensor.to(device) for tensor in [inputs, targets]]\r\n",
        "                targets = targets.long() # converts dtype to Long\r\n",
        "                output = self.network(inputs)\r\n",
        "                loss = self.loss_fn(output, targets.flatten())\r\n",
        "                # back propagation\r\n",
        "                loss.backward()\r\n",
        "                self.optimizer.step() # update model weights\r\n",
        "                train_loss += loss.data.item()\r\n",
        "                if (idx % 10 == 0) and verbose:\r\n",
        "                    print(f\"epoch {epoch+1}/{n_epochs}, batch {idx}.\")\r\n",
        "            train_loss = train_loss / len(train_loader)\r\n",
        "            train_losses.append(train_loss)\r\n",
        "           \r\n",
        "            # Validation \r\n",
        "            self.network.eval()        \r\n",
        "            for batch in val_loader:\r\n",
        "                inputs, targets = batch\r\n",
        "                inputs, targets = [tensor.to(device) for tensor in batch]\r\n",
        "                targets = targets.long() # converts dtype to Long\r\n",
        "                output = self.network(inputs)\r\n",
        "                loss = self.loss_fn(output, targets.flatten())\r\n",
        "                val_loss += loss.data.item()\r\n",
        "\r\n",
        "            val_loss = val_loss / len(val_loader)\r\n",
        "            val_losses.append(val_loss)\r\n",
        "\r\n",
        "            if val_loss < best_val_loss:\r\n",
        "              best_params = self.network.parameters()\r\n",
        "              best_val_loss = val_loss\r\n",
        "              best_val_epoch = epoch\r\n",
        "            \r\n",
        "            # If validation loss fails to decrease for some number of epochs\r\n",
        "            # end training\r\n",
        "            if np.abs(epoch - best_val_epoch) > early_stopping_buffer:\r\n",
        "              break\r\n",
        "        \r\n",
        "            print(f\"Epoch: {epoch}, Training Loss: {train_loss:.3f}, \"\r\n",
        "                 +f\"Validation loss: {val_loss:.3f}\")\r\n",
        "        \r\n",
        "        #self.network.parameters = best_params\r\n",
        "        self.best_val_loss = best_val_loss\r\n",
        "        self.best_val_epoch = best_val_epoch\r\n",
        "        if plot:\r\n",
        "            skip_frames = 3\r\n",
        "            fig, ax = plt.subplots()\r\n",
        "            fig.tight_layout()\r\n",
        "            if plot_train:\r\n",
        "              ax.plot(np.arange(epoch + 1)[skip_frames:], \r\n",
        "                      train_losses[skip_frames:], '-', label=\"training set\")\r\n",
        "            ax.plot(np.arange(epoch + 1)[skip_frames:], \r\n",
        "                    val_losses[skip_frames:], '-', label=\"test set\")\r\n",
        "            ax.set(xlabel=\"Epoch\", ylabel=\"Loss\")\r\n",
        "            ax.legend()\r\n",
        "            plt.show() \r\n",
        "    \r\n",
        "    # ----------------------------------\r\n",
        "    # Data preparation hooks\r\n",
        "    # ----------------------------------\r\n",
        "    def prepare_data(self):\r\n",
        "        \"\"\"\r\n",
        "        Args:\r\n",
        "            X : feature matrix\r\n",
        "            Y : target matrix\r\n",
        "        \"\"\"\r\n",
        "        X, Y = self.X, self.Y\r\n",
        "        global X_train, Y_train\r\n",
        "        global X_val, Y_val\r\n",
        "        global X_test, Y_test\r\n",
        "        splits = np.array([84, 15, 1]) / 100\r\n",
        "        train_size, val_size, test_size = splits\r\n",
        "        # train-test split\r\n",
        "        train_test_splits = model_selection.train_test_split(\r\n",
        "            X, Y, test_size = test_size, random_state = 42)\r\n",
        "        X_train, X_test, Y_train, Y_test = train_test_splits\r\n",
        "        # train-val split\r\n",
        "        relative_val_size = val_size / (train_size + val_size)\r\n",
        "        train_val_splits = model_selection.train_test_split(\r\n",
        "            X_train, Y_train, test_size = relative_val_size,\r\n",
        "            random_state = 42)\r\n",
        "        X_train, X_val, Y_train, Y_val = train_val_splits\r\n",
        "        assert X_train.shape[0] + X_val.shape[0] + X_test.shape[0] == X.shape[0] \r\n",
        "\r\n",
        "    def setup(self, stage=None):\r\n",
        "        if stage in [\"fit\", None]:\r\n",
        "            self.train_set = TabularDataset(X=X_train, Y=Y_train)\r\n",
        "            self.val_set = TabularDataset(X=X_val, Y=Y_val)\r\n",
        "        if stage in [\"test\", None]:\r\n",
        "            self.test_set = TabularDataset(X=X_test, Y=Y_test)\r\n",
        "\r\n",
        "    def get_dataloader(self, stage: str):\r\n",
        "        if stage == \"train\":\r\n",
        "            dataset = self.train_set\r\n",
        "        if stage == \"val\":\r\n",
        "            dataset = self.val_set\r\n",
        "        if stage == \"test\":\r\n",
        "            dataset = self.test_set\r\n",
        "        dl = torch.utils.data.DataLoader(\r\n",
        "            dataset = dataset, batch_size = self.BATCH_SIZE) \r\n",
        "        return dl \r\n",
        "        \r\n",
        "    def train_dataloader(self) -> torch.utils.data.DataLoader:\r\n",
        "        return self.get_dataloader(\"train\")\r\n",
        "    def val_dataloader(self) -> torch.utils.data.DataLoader:\r\n",
        "        return self.get_dataloader(\"val\")\r\n",
        "    def test_dataloader(self) -> torch.utils.data.DataLoader:\r\n",
        "        return self.get_dataloader(\"test\")\r\n",
        "    \r\n",
        "    # ----------------------------------\r\n",
        "    # Helper functions - Use post-training\r\n",
        "    # ----------------------------------\r\n",
        "    \r\n",
        "    def predict(self, x: torch.Tensor) -> torch.Tensor:\r\n",
        "        self.eval()\r\n",
        "        x.to(self.device)\r\n",
        "        logits = self(x)\r\n",
        "        preds = torch.argmax(input = logits, dim=1)\r\n",
        "        return preds\r\n",
        "\r\n",
        "    def accuracy(self, pred: torch.Tensor, target: torch.Tensor):\r\n",
        "        self.eval()\r\n",
        "        if isinstance(pred, torch.Tensor) and isinstance(target, torch.Tensor):\r\n",
        "            pred, target = [t.to(self.device) for t in [pred, target]]\r\n",
        "        elif isinstance(pred, np.ndarray) and isinstance(target, np.ndarray):\r\n",
        "            tensors = [torch.Tensor(t).to(self.device) for t in [pred, target]]\r\n",
        "            pred, target = tensors\r\n",
        "        else:\r\n",
        "            raise ValueError(\"The types of `pred` and `target` must match. \"\r\n",
        "                + \"These can be np.ndarrays or torch.Tensors.\")\r\n",
        "\r\n",
        "        accuracy = pl.metrics.functional.accuracy(pred, target)\r\n",
        "        return accuracy\r\n",
        "\r\n",
        "    def f1(self, pred: torch.Tensor, target: torch.Tensor):\r\n",
        "        self.eval()\r\n",
        "        if isinstance(pred, torch.Tensor) and isinstance(target, torch.Tensor):\r\n",
        "            pred, target = [t.to(self.device) for t in [pred, target]]\r\n",
        "        elif isinstance(pred, np.ndarray) and isinstance(target, np.ndarray):\r\n",
        "            tensors = [torch.Tensor(t).to(self.device) for t in [pred, target]]\r\n",
        "            pred, target = tensors\r\n",
        "        else:\r\n",
        "            raise ValueError(\"The types of `pred` and `target` must match. \"\r\n",
        "                + \"These can be np.ndarrays or torch.Tensors.\")\r\n",
        "        f1 = pl.metrics.functional.f1(\r\n",
        "            preds = pred, target = target, num_classes = 3, multilabel = True)\r\n",
        "        return f1\r\n",
        "        \r\n",
        "    def multiclass_aucroc(self, pred: torch.Tensor, target: torch.Tensor):\r\n",
        "        self.eval()\r\n",
        "        if isinstance(pred, torch.Tensor) and isinstance(target, torch.Tensor):\r\n",
        "            pred, target = [t.to(self.device) for t in [pred, target]]\r\n",
        "        elif isinstance(pred, np.ndarray) and isinstance(target, np.ndarray):\r\n",
        "            tensors = [torch.Tensor(t).to(self.device) for t in [pred, target]]\r\n",
        "            pred, target = tensors\r\n",
        "        else:\r\n",
        "            raise ValueError(\"The types of `pred` and `target` must match. \"\r\n",
        "                + \"These can be np.ndarrays or torch.Tensors.\")\r\n",
        "        auc_roc = pl.metrics.functional.classification.multiclass_auroc(\r\n",
        "            pred = pred, target = target)\r\n",
        "        return auc_roc\r\n",
        "\r\n",
        "    def plot_losses(self, plot_train=True):\r\n",
        "        skip_frames = 1\r\n",
        "        fig, ax = plt.subplots()\r\n",
        "        fig.tight_layout()\r\n",
        "\r\n",
        "        n_epochs = len(self.epoch_val_losses)\r\n",
        "        self.epoch_train_losses = [s.pop() for s in self.epoch_train_losses]\r\n",
        "        self.epoch_val_losses = [s.pop() for s in self.epoch_val_losses]\r\n",
        "        if plot_train:\r\n",
        "            n_epochs = len(self.epoch_train_losses)\r\n",
        "            ax.plot(np.arange(n_epochs)[skip_frames:], \r\n",
        "                    self.epoch_train_losses[skip_frames:], label=\"train\")\r\n",
        "        ax.plot(np.arange(n_epochs)[skip_frames:], \r\n",
        "                self.epoch_val_losses[1:][skip_frames:], label=\"val\")\r\n",
        "        ax.set(xlabel=\"Epoch\", ylabel=\"Loss\")\r\n",
        "        ax.legend()\r\n",
        "        plt.show()\r\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0lwJ8AwqgMt3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d6ca58b-0501-4ba9-cb5b-0ea443e2f45e"
      },
      "source": [
        "try:\r\n",
        "    print(f\"X.shape: {X.shape},\\tY.shape: {Y.shape}\")\r\n",
        "except:\r\n",
        "    pp = preprocessing.Preprocessing()\r\n",
        "    Y, names = pp.get_Y(data_path=data_path)\r\n",
        "    X = pd.read_csv(os.path.join(data_path, \"X.csv\"))\r\n",
        "    print(f\"X.shape: {X.shape},\\tY.shape: {Y.shape}\")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X.shape: (4061, 25869),\tY.shape: (4061, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OEkhFtZwlK2-"
      },
      "source": [
        "chi2 = feature_selection.chi2\n",
        "\n",
        "def X_r(r: int):\n",
        "    selectk = feature_selection.SelectKBest(chi2, k=r)\n",
        "    X_r: np.ndarray = selectk.fit_transform(X.values, Y.flatten()).astype(float)\n",
        "    return X_r\n",
        "\n",
        "R_VALS = [int(r) for r in [10, 100, 500, 1e3, 5e3, 10e3, 25e3]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHwnsvdxPCyC"
      },
      "source": [
        "REAL_DATA = X_r[R_VALS[0]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_ifKBbA9Hhw"
      },
      "source": [
        "def PCA_req_components(X: np.ndarray, threshold = 0.99, plot=True, verbose=False):\r\n",
        "    n_samples, n_features = X.shape[0], X.shape[1]\r\n",
        "    components = min({n_samples, n_features})\r\n",
        "    if n_features < components:\r\n",
        "        components = n_features\r\n",
        "    pca = decomposition.PCA(n_components = components)\r\n",
        "    pca.fit(X)\r\n",
        "    \r\n",
        "    cusum = np.cumsum(pca.explained_variance_ratio_)\r\n",
        "    threshold_line = np.ones(components) * threshold\r\n",
        "    p_components = np.arange(components) + 1\r\n",
        "    if plot:\r\n",
        "        fig, ax = plt.subplots(figsize=(8, 6))\r\n",
        "        ax.plot(p_components, cusum, label='cumulative variance explained')\r\n",
        "        ax.plot(p_components, threshold_line, '--', label='threshold')\r\n",
        "        # ax.plot(p_components, pca.explained_variance_ratio_, 'o', \r\n",
        "        #         label='individual variance explained')\r\n",
        "        ax.set(title = f\"Variance Explained, n_features = {n_features}\",\r\n",
        "               xlabel = \"Principal components\", \r\n",
        "               ylabel = \"Percentage of Variance Explained\")\r\n",
        "        ax.legend()\r\n",
        "        plt.show()\r\n",
        "\r\n",
        "    reduced_components = list(cusum >= threshold).index(True)\r\n",
        "    # Thresholds, required components table\r\n",
        "    thresholds = [0.9, 0.95, 0.97, 0.99, 0.999]\r\n",
        "    idx = []\r\n",
        "    for t in thresholds:\r\n",
        "        idx.append(list(cusum >= t).index(True))\r\n",
        "    thresholds, idx = [np.array(l) for l in [thresholds, idx]]\r\n",
        "    req_components = pd.DataFrame(np.vstack([thresholds, idx]),\r\n",
        "                                  index = [\"threshold\", \"principal components\"])\r\n",
        "    return req_components\r\n",
        "\r\n",
        "def PCA_reduction(X: np.ndarray, n: int) -> np.ndarray:\r\n",
        "    \"\"\" Transforms a feature matrix with PCA feature reduction.\r\n",
        "    Args:\r\n",
        "        X (np.ndarray): Feature matrix\r\n",
        "        n (int): number of principal axis components\r\n",
        "    Returns:\r\n",
        "        X_new (np.ndarray): X with PCA feature reduction.\r\n",
        "    \"\"\"\r\n",
        "    n_samples, n_features = X.shape[0], X.shape[1]\r\n",
        "    pca = decomposition.PCA(n_components = n)\r\n",
        "    X_new = pca.fit_transform(X)\r\n",
        "    return X_new"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8NQrTf1Ir__"
      },
      "source": [
        "# for r in R_VALS:\r\n",
        "#     req_components = PCA_req_components(X_r(r), plot = True, verbose = True)\r\n",
        "#     print(f\"r: {r}\")\r\n",
        "#     print(req_components)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cxIdTg9Ldpu0"
      },
      "source": [
        "### Example outputs: \r\n",
        "\r\n",
        "The following results come from using the X in `data/X.csv` with methods defined above and running\r\n",
        "\r\n",
        "```python\r\n",
        "for r in R_VALS:\r\n",
        "    req_components = PCA_req_components(X_r(r), plot = True, verbose = True)\r\n",
        "    print(f\"r: {r}\")\r\n",
        "    print(req_components)\r\n",
        "```\r\n",
        "\r\n",
        "![alt text][r10]\r\n",
        "\r\n",
        "```\r\n",
        "r: 10\r\n",
        "                        0     1     2     3      4\r\n",
        "threshold             0.9  0.95  0.97  0.99  0.999\r\n",
        "principal components  0.0  0.00  0.00  2.00  6.000\r\n",
        "```\r\n",
        "\r\n",
        "![alt text][r100]\r\n",
        "\r\n",
        "```\r\n",
        "r: 100\r\n",
        "threshold             0.9  0.95  0.97   0.99   0.999\r\n",
        "principal components  0.0  0.00  3.00  18.00  55.000\r\n",
        "```\r\n",
        "\r\n",
        "![alt text][r500]\r\n",
        "\r\n",
        "\r\n",
        "```\r\n",
        "r: 500\r\n",
        "threshold             0.9  0.95   0.97   0.99    0.999\r\n",
        "principal components  0.0  6.00  22.00  83.00  258.000\r\n",
        "```\r\n",
        "\r\n",
        "![alt text][r1k]\r\n",
        "\r\n",
        "```\r\n",
        "r: 1000\r\n",
        "threshold             0.9   0.95   0.97    0.99    0.999\r\n",
        "principal components  1.0  29.00  65.00  182.00  511.000\r\n",
        "```\r\n",
        "\r\n",
        "![alt text][r5k]\r\n",
        "\r\n",
        "```\r\n",
        "r: 5000\r\n",
        "threshold               0.9    0.95    0.97     0.99     0.999\r\n",
        "principal components  135.0  329.00  519.00  1024.00  2149.000\r\n",
        "```\r\n",
        "\r\n",
        "![alt text][r10k]\r\n",
        "\r\n",
        "```\r\n",
        "r: 10000\r\n",
        "threshold               0.9    0.95     0.97     0.99     0.999\r\n",
        "principal components  359.0  702.00  1008.00  1750.00  3112.000\r\n",
        "```\r\n",
        "\r\n",
        "![alt text][r25k]\r\n",
        "\r\n",
        "```\r\n",
        "r: 25000\r\n",
        "threshold               0.9     0.95     0.97     0.99     0.999\r\n",
        "principal components  903.0  1481.00  1934.00  2818.00  3809.000\r\n",
        "```\r\n",
        "\r\n",
        "[r10]: https://github.com/Unique-Divine/Neural-Networks-for-Genomic-Risk/raw/master/images/var_explained-r10.png \"\"\r\n",
        "\r\n",
        "[r100]: https://github.com/Unique-Divine/Neural-Networks-for-Genomic-Risk/raw/master/images/var_explained-r100.png \"\"\r\n",
        "\r\n",
        "[r500]: https://github.com/Unique-Divine/Neural-Networks-for-Genomic-Risk/raw/master/images/var_explained-r500.png \"\"\r\n",
        "\r\n",
        "[r1k]: https://github.com/Unique-Divine/Neural-Networks-for-Genomic-Risk/raw/master/images/var_explained-r1k.png \"\"\r\n",
        "\r\n",
        "[r5k]: https://github.com/Unique-Divine/Neural-Networks-for-Genomic-Risk/raw/master/images/var_explained-r5k.png \"\"\r\n",
        "\r\n",
        "[r10k]: https://github.com/Unique-Divine/Neural-Networks-for-Genomic-Risk/raw/master/images/var_explained-r10k.png \"\"\r\n",
        "\r\n",
        "[r25k]: https://github.com/Unique-Divine/Neural-Networks-for-Genomic-Risk/raw/master/images/var_explained-r25k.png \"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JoW3efWUjV--"
      },
      "source": [
        "---\r\n",
        "\r\n",
        "# Data set balance analysis\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F87N39ggj4Za"
      },
      "source": [
        ""
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "id": "zNAi6qaZjbRT",
        "outputId": "077ea26d-4625-4d72-ad0d-a3d6eca0fd5e"
      },
      "source": [
        "np.set_printoptions(precision = 3)\r\n",
        "def balance_check(Y: np.ndarray = Y, verbose=True):\r\n",
        "    y = pd.Series(Y.flatten(), dtype=int)\r\n",
        "    counts = np.array([c for c in [y.value_counts()]]).flatten()\r\n",
        "    pcts = counts / counts.sum() * 100\r\n",
        "    labels = y.unique()\r\n",
        "    if verbose:\r\n",
        "        print(\"counts: {}\\npcts: {}\\nlabels: {}\".format(\r\n",
        "        counts, pcts, labels))\r\n",
        "    fig, ax = plt.subplots(figsize = (8, 6))\r\n",
        "    ax.bar(labels, pcts, width=0.2);\r\n",
        "    sweetspot = 1 / labels.size * 100\r\n",
        "    sweetspot_line = np.ones(50) * sweetspot\r\n",
        "    ax.plot(np.linspace(labels[0], labels[-1]), sweetspot_line, 'r--')\r\n",
        "    ax.set(xlabel = \"\")\r\n",
        "    ax.grid()\r\n",
        "    plt.show()\r\n",
        "    return counts, pcts, labels\r\n",
        "balance_check()"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "counts: [1575 1372 1114]\n",
            "pcts: [38.784 33.785 27.432]\n",
            "labels: [0 1 2]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([1575, 1372, 1114]), array([38.784, 33.785, 27.432]), array([0, 1, 2]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08LYuvqDOyS_"
      },
      "source": [
        "---\n",
        "\n",
        "# Evaluating GAN reasonable GAN parameters\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kEDkhFjMOjiG"
      },
      "source": [
        "REAL_DATA = X_new"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jNE4OqAIvPZz",
        "outputId": "32194cc7-9df8-4fab-9a60-5d0791c045b6"
      },
      "source": [
        "start_time = time.time()\r\n",
        "g = gans.TabularGANs(\r\n",
        "        X = REAL_DATA, Y = Y, \r\n",
        "        gen_dim = (100, 100),\r\n",
        "        dis_dim = (10, 10),\r\n",
        "        embedding_dim = 1000,\r\n",
        "        epochs = 2, \r\n",
        "        l2scale = 1e-4,\r\n",
        "        batch_size = 500)\r\n",
        "g.train_GANs()\r\n",
        "current_time = time.time() - start_time\r\n",
        "print(f\"training took {current_time:.1f}s\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training took 4.1s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Jj7X3h2xASu",
        "outputId": "ca77a9b3-03c6-48a0-e078-4e417dc4098e"
      },
      "source": [
        "def eval_test(real_x, real_y, generator_model: gans.TabularGANs) -> float:\r\n",
        "    \"\"\"\r\n",
        "    \"\"\"\r\n",
        "    # prepare real data\r\n",
        "    real_y = real_y.reshape(-1, 1)\r\n",
        "    real_data = np.hstack([real_x, real_y]).astype(float)\r\n",
        "    # prepare synth data\r\n",
        "    sx, sy = g.create_synth_samples(REAL_DATA.shape[0])\r\n",
        "    sy = sy.reshape(-1, 1)\r\n",
        "    s = np.hstack([sx, sy]).astype(float)\r\n",
        "    # evaluate\r\n",
        "    eval: dict = g.evaluate_synth_data(\r\n",
        "        synth_data = pd.DataFrame(s), \r\n",
        "        real_data = pd.DataFrame(real_data), \r\n",
        "        aggregate = False)\r\n",
        "    eval: float = list(eval.values())[0]\r\n",
        "    return eval\r\n",
        "eval_test(REAL_DATA, Y, g)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.623211599768234"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 149
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2lKGzljBhBg6"
      },
      "source": [
        "GAN_TESTS = {}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fgWbyVkeP7D8"
      },
      "source": [
        "def gan_parameter_test(real_x, real_y, generator_model: gans.TabularGANs, tests=5):\r\n",
        "    original_model = generator_model\r\n",
        "    parameters = generator_model.params\r\n",
        "    evaluations = np.empty(tests)\r\n",
        "    for test in range(tests):\r\n",
        "        start_time = time.time()\r\n",
        "        test_model = original_model\r\n",
        "        test_model.train_GANs()\r\n",
        "        current_time = time.time() - start_time\r\n",
        "        eta = current_time * (tests - test) \r\n",
        "        print(f\"Training step speed {current_time:.1f} s\"\r\n",
        "            + f\"\\tETA: {eta:.1f} s\")\r\n",
        "\r\n",
        "        evaluation = eval_test(real_x, real_y, generator_model)\r\n",
        "        evaluations[test] = evaluation\r\n",
        "    score = evaluations.mean()\r\n",
        "    GAN_TESTS[score] = parameters"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qavsPIamUx5G"
      },
      "source": [
        "g = gans.TabularGANs(\r\n",
        "    X = REAL_DATA, Y = Y, \r\n",
        "    gen_dim = (20, 20),\r\n",
        "    dis_dim = (50, 50),\r\n",
        "    embedding_dim = 100,\r\n",
        "    epochs = 75, \r\n",
        "    l2scale = 1e-4,\r\n",
        "    batch_size = 500)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f5yQG4HJHusJ",
        "outputId": "b8a0014b-583c-4d29-da90-5cfc13b26ce2"
      },
      "source": [
        "gan_parameter_test(REAL_DATA, Y, g)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training step speed 16.4 s\tETA: 81.9 s\n",
            "Training step speed 14.2 s\tETA: 56.9 s\n",
            "Training step speed 14.1 s\tETA: 42.2 s\n",
            "Training step speed 14.4 s\tETA: 28.9 s\n",
            "Training step speed 14.2 s\tETA: 14.2 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2DyENXD9cHdX"
      },
      "source": [
        "def save_gan_tests(overwrite = False):\r\n",
        "    if os.path.exists(os.path.join(data_path, \"gan_params.p\")) == False:\r\n",
        "        with open(os.path.join(data_path, \"gan_params.p\"), 'wb') as fp:\r\n",
        "            pickle.dump(GAN_TESTS, fp, protocol=pickle.HIGHEST_PROTOCOL)\r\n",
        "        print(\"Parameters saved.\")\r\n",
        "    if overwrite:\r\n",
        "        with open(os.path.join(data_path, \"gan_params.p\"), 'wb') as fp:\r\n",
        "            pickle.dump(GAN_TESTS, fp, protocol=pickle.HIGHEST_PROTOCOL)\r\n",
        "    else:\r\n",
        "        print(\"The parameters were already saved previously.\" \r\n",
        "            + \"To overwrite the save, set `overwrite = True`.\")\r\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_DzphjZNcfUv",
        "outputId": "c48dc6d5-eabf-4ee1-94db-1ae771298d20"
      },
      "source": [
        "def load_gan_tests() -> dict:\r\n",
        "    with open(os.path.join(data_path, \"gan_params.p\"), 'rb') as fp:\r\n",
        "        gan_params: dict = pickle.load(fp)\r\n",
        "    return gan_params\r\n",
        "load_gan_tests()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0.5674040020528077: {'batch_size': 500,\n",
              "  'dis_dim': (50, 50),\n",
              "  'embedding_dim': 100,\n",
              "  'epochs': 75,\n",
              "  'gen_dim': (20, 20),\n",
              "  'l2scale': 0.0001},\n",
              " 0.5685682816354259: {'batch_size': 500,\n",
              "  'dis_dim': (50, 50),\n",
              "  'embedding_dim': 100,\n",
              "  'epochs': 50,\n",
              "  'gen_dim': (20, 20),\n",
              "  'l2scale': 0.0001},\n",
              " 0.5749121749272297: {'batch_size': 500,\n",
              "  'dis_dim': (50, 50),\n",
              "  'embedding_dim': 100,\n",
              "  'epochs': 5,\n",
              "  'gen_dim': (5, 5),\n",
              "  'l2scale': 0.0001},\n",
              " 0.576530821340115: {'batch_size': 500,\n",
              "  'dis_dim': (50, 50),\n",
              "  'embedding_dim': 100,\n",
              "  'epochs': 100,\n",
              "  'gen_dim': (20, 20),\n",
              "  'l2scale': 0.0001},\n",
              " 0.5785666217070802: {'batch_size': 500,\n",
              "  'dis_dim': (50, 50),\n",
              "  'embedding_dim': 100,\n",
              "  'epochs': 25,\n",
              "  'gen_dim': (20, 20),\n",
              "  'l2scale': 0.0001},\n",
              " 0.5865022262111977: {'batch_size': 500,\n",
              "  'dis_dim': (50, 50),\n",
              "  'embedding_dim': 100,\n",
              "  'epochs': 10,\n",
              "  'gen_dim': (20, 20),\n",
              "  'l2scale': 0.0001},\n",
              " 0.5870081627287909: {'batch_size': 500,\n",
              "  'dis_dim': (50, 50),\n",
              "  'embedding_dim': 100,\n",
              "  'epochs': 5,\n",
              "  'gen_dim': (20, 20),\n",
              "  'l2scale': 0.0001},\n",
              " 0.5877103068395282: {'batch_size': 500,\n",
              "  'dis_dim': (50, 50),\n",
              "  'embedding_dim': 100,\n",
              "  'epochs': 5,\n",
              "  'gen_dim': (10, 10),\n",
              "  'l2scale': 0.0001},\n",
              " 0.5989898807675941: {'batch_size': 500,\n",
              "  'dis_dim': (50, 50),\n",
              "  'embedding_dim': 100,\n",
              "  'epochs': 5,\n",
              "  'gen_dim': (50, 50),\n",
              "  'l2scale': 0.0001},\n",
              " 0.6026186747617391: {'batch_size': 500,\n",
              "  'dis_dim': (5, 5),\n",
              "  'embedding_dim': 100,\n",
              "  'epochs': 5,\n",
              "  'gen_dim': (20, 20),\n",
              "  'l2scale': 0.0001},\n",
              " 0.6047613809301506: {'batch_size': 500,\n",
              "  'dis_dim': (50, 50),\n",
              "  'embedding_dim': 800,\n",
              "  'epochs': 5,\n",
              "  'gen_dim': (20, 20),\n",
              "  'l2scale': 0.0001},\n",
              " 0.6072181078327212: {'batch_size': 500,\n",
              "  'dis_dim': (5, 5),\n",
              "  'embedding_dim': 100,\n",
              "  'epochs': 5,\n",
              "  'gen_dim': (5, 5),\n",
              "  'l2scale': 0.0001},\n",
              " 0.6077451991831262: {'batch_size': 500,\n",
              "  'dis_dim': (50, 50),\n",
              "  'embedding_dim': 100,\n",
              "  'epochs': 10,\n",
              "  'gen_dim': (5, 5),\n",
              "  'l2scale': 0.0001},\n",
              " 0.6107637472679167: {'batch_size': 500,\n",
              "  'dis_dim': (50, 50),\n",
              "  'embedding_dim': 50,\n",
              "  'epochs': 5,\n",
              "  'gen_dim': (50, 50),\n",
              "  'l2scale': 0.0001},\n",
              " 0.6113756274600075: {'batch_size': 500,\n",
              "  'dis_dim': (50, 50),\n",
              "  'embedding_dim': 300,\n",
              "  'epochs': 5,\n",
              "  'gen_dim': (20, 20),\n",
              "  'l2scale': 0.0001},\n",
              " 0.6159734824740083: {'batch_size': 500,\n",
              "  'dis_dim': (50, 50),\n",
              "  'embedding_dim': 150,\n",
              "  'epochs': 5,\n",
              "  'gen_dim': (20, 20),\n",
              "  'l2scale': 0.0001},\n",
              " 0.6218641415404881: {'batch_size': 500,\n",
              "  'dis_dim': (50, 50),\n",
              "  'embedding_dim': 2000,\n",
              "  'epochs': 2,\n",
              "  'gen_dim': (50, 50),\n",
              "  'l2scale': 0.0001},\n",
              " 0.6340404356579844: {'batch_size': 500,\n",
              "  'dis_dim': (20, 20),\n",
              "  'embedding_dim': 100,\n",
              "  'epochs': 5,\n",
              "  'gen_dim': (20, 20),\n",
              "  'l2scale': 0.0001},\n",
              " 0.6378401806200024: {'batch_size': 500,\n",
              "  'dis_dim': (20, 20),\n",
              "  'embedding_dim': 100,\n",
              "  'epochs': 5,\n",
              "  'gen_dim': (20, 20),\n",
              "  'l2scale': 0.0001},\n",
              " 0.647099619665503: {'batch_size': 500,\n",
              "  'dis_dim': (50, 50),\n",
              "  'embedding_dim': 100,\n",
              "  'epochs': 2,\n",
              "  'gen_dim': (50, 50),\n",
              "  'l2scale': 0.0001},\n",
              " 0.6471713985608973: {'batch_size': 500,\n",
              "  'dis_dim': (50, 50),\n",
              "  'embedding_dim': 500,\n",
              "  'epochs': 2,\n",
              "  'gen_dim': (50, 50),\n",
              "  'l2scale': 0.0001},\n",
              " 0.6547640939840887: {'batch_size': 500,\n",
              "  'dis_dim': (50, 50),\n",
              "  'embedding_dim': 50,\n",
              "  'epochs': 2,\n",
              "  'gen_dim': (50, 50),\n",
              "  'l2scale': 0.0001},\n",
              " 0.6612323123913957: {'batch_size': 500,\n",
              "  'dis_dim': (100, 100),\n",
              "  'embedding_dim': 1000,\n",
              "  'epochs': 2,\n",
              "  'gen_dim': (50, 50),\n",
              "  'l2scale': 0.0001},\n",
              " 0.6645767740594659: {'batch_size': 500,\n",
              "  'dis_dim': (50, 50),\n",
              "  'embedding_dim': 1000,\n",
              "  'epochs': 2,\n",
              "  'gen_dim': (50, 50),\n",
              "  'l2scale': 0.0001},\n",
              " 0.6647243471002036: {'batch_size': 500,\n",
              "  'dis_dim': (50, 50),\n",
              "  'embedding_dim': 1000,\n",
              "  'epochs': 2,\n",
              "  'gen_dim': (100, 100),\n",
              "  'l2scale': 0.0001}}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 255
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mqM12yfhV9-J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e32e930-821e-4ec5-f883-f3333ac86914"
      },
      "source": [
        "try:\n",
        "    print(gan_model.GANs, \"\\nGANs are already trained.\")\n",
        "except: \n",
        "    gan_model = gans.TabularGANs(\n",
        "        X = REAL_DATA, Y = Y, \n",
        "        epochs = 100)\n",
        "    print(\"training GANs...\")\n",
        "    gan_model.train_GANs()\n",
        "    print(f\"GANs trained.\\n{ml.GANs}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training GANs...\n",
            "GANs trained.\n",
            "<ctgan.synthesizer.CTGANSynthesizer object at 0x7f140a95c5c0>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDu0qmCUqR_4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "outputId": "5899636f-5d2c-46ac-b6a6-2f3c0435713b"
      },
      "source": [
        "X_fake, Y_fake = ml.getFakeSamples(n = 1000)\r\n",
        "print(X_fake.shape)\r\n",
        "Y_fake = np.around(Y_fake).astype(int)\r\n",
        "scaler = sklearn.preprocessing.MinMaxScaler()\r\n",
        "X_fake = scaler.fit_transform(X_fake)\r\n",
        "print(np.array([arr.shape for arr in [X_fake, Y_fake]]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-ec794ed01a4f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_fake\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_fake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetFakeSamples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_fake\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mY_fake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_fake\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mscaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMinMaxScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mX_fake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_fake\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'ml' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BBGdG_xFtzpx"
      },
      "source": [
        "---\n",
        "\n",
        "# Predictive Modeling\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 763
        },
        "id": "hNFybaCXsiju",
        "outputId": "f11b10d9-3a26-409c-d153-1736010bb234"
      },
      "source": [
        "network = LitFFNN(X = X_fake, Y = Y_fake, data_dir=data_path)\r\n",
        "trainer = pl.Trainer(max_epochs = 4, gpus = 0, fast_dev_run = True, \r\n",
        "    progress_bar_refresh_rate = 50)\r\n",
        "trainer.fit(network)\r\n",
        "network.plot_losses(plot_train = True)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-16-b7c1faecba81>\", line 1, in <module>\n",
            "    network = LitFFNN(X = X_fake, Y = Y_fake, data_dir=data_path)\n",
            "NameError: name 'X_fake' is not defined\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 1823, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'NameError' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 1132, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 313, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 358, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "  File \"/usr/lib/python3.6/inspect.py\", line 1490, in getinnerframes\n",
            "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
            "  File \"/usr/lib/python3.6/inspect.py\", line 1448, in getframeinfo\n",
            "    filename = getsourcefile(frame) or getfile(frame)\n",
            "  File \"/usr/lib/python3.6/inspect.py\", line 696, in getsourcefile\n",
            "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
            "  File \"/usr/lib/python3.6/inspect.py\", line 742, in getmodule\n",
            "    os.path.realpath(f)] = module.__name__\n",
            "  File \"/usr/lib/python3.6/posixpath.py\", line 395, in realpath\n",
            "    path, ok = _joinrealpath(filename[:0], filename, {})\n",
            "  File \"/usr/lib/python3.6/posixpath.py\", line 429, in _joinrealpath\n",
            "    if not islink(newpath):\n",
            "  File \"/usr/lib/python3.6/posixpath.py\", line 171, in islink\n",
            "    st = os.lstat(path)\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8AA3OUIJH6Mp",
        "outputId": "446ac6c0-4331-4a77-ccb1-fd289c1345c8"
      },
      "source": [
        "pred = network.predict(torch.Tensor(X_r))\r\n",
        "network.accuracy(pred, torch.Tensor(Y))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.3755)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wK_P_ZvqxQ7w"
      },
      "source": [
        "def test_training_method(verbose = False):\r\n",
        "    print(\"Testing training method: \")\r\n",
        "    network = LitFFNN(X = X_fake, Y = Y_fake, data_dir=data_path)\r\n",
        "    trainer = pl.Trainer(max_epochs = 4, gpus = 0, fast_dev_run=True, \r\n",
        "                         progress_bar_refresh_rate = 0)\r\n",
        "    trainer.fit(network)\r\n",
        "    if verbose:\r\n",
        "        print(network)\r\n",
        "    print(\"Test passed!\\n\")\r\n",
        "\r\n",
        "def test_output_consistency():\r\n",
        "    print(\"Testing model output consistency:\")\r\n",
        "    network = LitFFNN(X_r, Y)\r\n",
        "    preds = []\r\n",
        "    for i in range(2):\r\n",
        "        pred = network.predict(torch.Tensor(X_r))\r\n",
        "        preds.append(pred)\r\n",
        "\r\n",
        "    overlap = np.array((preds[0] == preds[1]))\r\n",
        "    t = overlap.sum() \r\n",
        "    f = overlap.size - t\r\n",
        "    t, f = np.array([t, f]) / (t  + f) \r\n",
        "    print(f\"Matched: {t:.2f} %,\\tMismatched: {f:.2f} %.\\n\")\r\n",
        "\r\n",
        "test_output_consistency()\r\n",
        "test_training_method()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NAWDYcter-6i"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ThYb04f-620M"
      },
      "source": [
        "\r\n",
        "# Train and evaluate neural network\r\n",
        "\r\n",
        "# Train and evaluate linear SVC\r\n",
        "\r\n",
        "# Train and evaluate XGB Classifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WiwqJdnKTwwh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QcdXgoOZL01L"
      },
      "source": [
        "```python\r\n",
        "# ckpt\r\n",
        "import logging\r\n",
        "import torch.multiprocessing as mp\r\n",
        "from torch.multiprocessing import Manager\r\n",
        "from tqdm import tqdm\r\n",
        "import time\r\n",
        "#mp.set_start_method('spawn')# good solution !!!!\r\n",
        "\r\n",
        "logging.getLogger('lightning').setLevel(0)\r\n",
        "\r\n",
        "early_stop_callback = EarlyStopping(\r\n",
        "   monitor='val_acc',\r\n",
        "   min_delta=0.00,\r\n",
        "   patience=5,\r\n",
        "   verbose=False,\r\n",
        "   mode='max'\r\n",
        ")\r\n",
        "\r\n",
        "\r\n",
        "def train_model(accuracies, rank):\r\n",
        "  start_time = time.time()\r\n",
        "  print('rank: ', rank)\r\n",
        "  A, indices = sample_from_data(100)\r\n",
        "  model = LitFFNN(X = A, Y = Y, \r\n",
        "      data_dir = os.path.join(data_path, \"temp\"))\r\n",
        "  trainer = pl.Trainer(gpus = 0, max_epochs=10, \r\n",
        "      progress_bar_refresh_rate=50, weights_summary=None,\r\n",
        "      callbacks=[early_stop_callback], num_sanity_val_steps=0)\r\n",
        "  trainer.fit(model)\r\n",
        "  acc = model.accuracy(\r\n",
        "    y_hat = model.predict(torch.Tensor(A.astype(float))),\r\n",
        "    y = torch.Tensor(Y.astype(float))).item()\r\n",
        "  accuracies.append(acc)\r\n",
        "\r\n",
        "with Manager() as manager:\r\n",
        "  accuracies = manager.list()  # <-- can be shared between processes.\r\n",
        "  indices = manager.list()  # <-- can be shared between processes.\r\n",
        "  processes = []\r\n",
        "  num_processes = 10\r\n",
        "  for i in tqdm(range(1)):\r\n",
        "    for rank in range(num_processes):\r\n",
        "      p = mp.Process(target=train_model, args=(accuracies, rank,))\r\n",
        "      p.start()\r\n",
        "      processes.append(p)\r\n",
        "    for p in processes:\r\n",
        "      p.join()\r\n",
        "  accuracies = list(accuracies)\r\n",
        "  ```"
      ]
    }
  ]
}