{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#CTGAN\" data-toc-modified-id=\"CTGAN-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>CTGAN</a></span><ul class=\"toc-item\"><li><span><a href=\"#Generate-sythetic-data\" data-toc-modified-id=\"Generate-sythetic-data-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Generate sythetic data</a></span></li></ul></li><li><span><a href=\"#References-(GANs)\" data-toc-modified-id=\"References-(GANs)-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>References (GANs)</a></span></li><li><span><a href=\"#TODO\" data-toc-modified-id=\"TODO-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>TODO</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import PyTorch\n",
    "import torch\n",
    "\n",
    "# standard DS stack\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "import pandas as pd\n",
    "# embed static images in the ipynb\n",
    "%matplotlib inline \n",
    "\n",
    "# neural network package\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "\n",
    "# computer vision\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "# dataset loading\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# convenient package for plotting loss functions\n",
    "# from livelossplot import PlotLosses\n",
    "\n",
    "import copy\n",
    "import importlib.util # to run outside module\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve preprocessed titanic dataset\n",
    "system_path = r\"C:\\Users\\uniqu\\Adaptation\\github repos\" \\\n",
    "              + \"\\Bioinformatics-Neural Networks for Genomic Risk\"\n",
    "\n",
    "exec(open(system_path+\"\\preprocess_titanic.py\").read())\n",
    "\n",
    "X, Y, col_names = preprocess_titanic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature names:\n",
      "  ['pclass', 'sex', 'age', 'sibsp', 'parch', 'fare', 'embarked', 'class', 'who', 'adult_male', 'embark_town', 'alone']\n",
      "\n",
      "target names: 'survived'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([ 3.  ,  1.  , 22.  ,  1.  ,  0.  ,  7.25,  0.  ,  0.  ,  1.  ,\n",
       "         0.  ,  0.  ,  0.  ,  1.  ,  0.  ,  0.  ,  1.  ,  0.  ,  1.  ,\n",
       "         0.  ,  0.  ,  1.  ]),\n",
       " array([0.]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Real (toy) dataset\n",
    "def get_real_data(X, Y):\n",
    "    \"\"\"[summary]\n",
    "\n",
    "    Args:\n",
    "        X, Y (np.ndarray): feature & target matrices.\n",
    "\n",
    "    Returns:\n",
    "        [type]: [description]\n",
    "    \"\"\"\n",
    "    # feature_names = list(dataset.columns)[1:]\n",
    "    # target_names = list(dataset.columns)[0]\n",
    "    \n",
    "    # Perform train-test split\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "        X, Y, test_size=0.3, random_state=7)\n",
    "\n",
    "    real_data = np.hstack([Y, X])\n",
    "    train_data = np.hstack([Y_train, X_train])\n",
    "    test_data = np.hstack([Y_test, X_test])\n",
    "        \n",
    "    return real_data, train_data, test_data\n",
    "\n",
    "real_data, train_data, test_data = get_real_data(X, Y, titanic_data)\n",
    "\n",
    "print(f\"feature names:\\n  {list(titanic_data.columns[1:])}\\n\")\n",
    "print(f\"target names: '{titanic_data.columns[0]}'\")\n",
    "X[0], Y[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CTGAN\n",
    "\n",
    "[TGAN](https://github.com/sdv-dev/TGAN) seemed like the exact tool I was looking for. It turns out [CTGAN](https://github.com/sdv-dev/CTGAN) is better. Several major differences make CTGAN outperform TGAN.\n",
    "- **Preprocessing**: CTGAN uses more sophisticated Variational Gaussian Mixture Model to detect modes of continuous columns.\n",
    "- **Network structure**: TGAN uses LSTM to generate synthetic data column by column. CTGAN uses Fully-connected networks which is more efficient.\n",
    "- **Features to prevent** mode collapse: We design a conditional generator and resample the training data to prevent model collapse on discrete columns. We use WGANGP and PacGAN to stabilize the training of GAN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from ctgan import load_demo\n",
    "data = load_demo()\n",
    "\n",
    "from ctgan import CTGANSynthesizer\n",
    "ctgan = CTGANSynthesizer()\n",
    "\n",
    "# CTGAN Synthesizer models: G & D\n",
    "# Fit the models to the training data\n",
    "ctgan.fit(train_data=train_data,\n",
    "          epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate sythetic data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>alone</th>\n",
       "      <th>who_child</th>\n",
       "      <th>who_man</th>\n",
       "      <th>...</th>\n",
       "      <th>embark_town_Queenstown</th>\n",
       "      <th>embark_town_Southampton</th>\n",
       "      <th>embarked_C</th>\n",
       "      <th>embarked_Q</th>\n",
       "      <th>embarked_S</th>\n",
       "      <th>adult_male_False</th>\n",
       "      <th>adult_male_True</th>\n",
       "      <th>class_First</th>\n",
       "      <th>class_Second</th>\n",
       "      <th>class_Third</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.080237</td>\n",
       "      <td>0.791131</td>\n",
       "      <td>1.063448</td>\n",
       "      <td>28.413202</td>\n",
       "      <td>0.771792</td>\n",
       "      <td>-0.021365</td>\n",
       "      <td>34.495780</td>\n",
       "      <td>1.035639</td>\n",
       "      <td>-0.023513</td>\n",
       "      <td>1.014079</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013898</td>\n",
       "      <td>0.145945</td>\n",
       "      <td>0.935486</td>\n",
       "      <td>0.028479</td>\n",
       "      <td>-0.073765</td>\n",
       "      <td>-0.120157</td>\n",
       "      <td>0.918098</td>\n",
       "      <td>0.867076</td>\n",
       "      <td>-0.033363</td>\n",
       "      <td>1.104807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.917577</td>\n",
       "      <td>2.145518</td>\n",
       "      <td>1.065295</td>\n",
       "      <td>19.750091</td>\n",
       "      <td>2.596427</td>\n",
       "      <td>-0.150105</td>\n",
       "      <td>91.814781</td>\n",
       "      <td>0.891793</td>\n",
       "      <td>0.026567</td>\n",
       "      <td>1.029313</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004099</td>\n",
       "      <td>0.930086</td>\n",
       "      <td>-0.006607</td>\n",
       "      <td>0.998861</td>\n",
       "      <td>0.968039</td>\n",
       "      <td>-0.073928</td>\n",
       "      <td>0.999255</td>\n",
       "      <td>0.000214</td>\n",
       "      <td>0.062596</td>\n",
       "      <td>1.018597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.855402</td>\n",
       "      <td>3.106432</td>\n",
       "      <td>-0.123146</td>\n",
       "      <td>20.296845</td>\n",
       "      <td>3.790539</td>\n",
       "      <td>0.800693</td>\n",
       "      <td>7.423602</td>\n",
       "      <td>0.947184</td>\n",
       "      <td>0.775650</td>\n",
       "      <td>1.025470</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009357</td>\n",
       "      <td>0.931154</td>\n",
       "      <td>-0.045928</td>\n",
       "      <td>1.174743</td>\n",
       "      <td>0.980231</td>\n",
       "      <td>1.004876</td>\n",
       "      <td>-0.096677</td>\n",
       "      <td>-0.038539</td>\n",
       "      <td>0.048083</td>\n",
       "      <td>0.020445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.012989</td>\n",
       "      <td>1.833180</td>\n",
       "      <td>1.018224</td>\n",
       "      <td>33.280963</td>\n",
       "      <td>-0.145543</td>\n",
       "      <td>0.068389</td>\n",
       "      <td>7.426653</td>\n",
       "      <td>-0.132893</td>\n",
       "      <td>-0.024482</td>\n",
       "      <td>0.983342</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008880</td>\n",
       "      <td>1.037112</td>\n",
       "      <td>-0.056452</td>\n",
       "      <td>-0.008572</td>\n",
       "      <td>0.041343</td>\n",
       "      <td>-0.073893</td>\n",
       "      <td>-0.048799</td>\n",
       "      <td>0.772480</td>\n",
       "      <td>0.057497</td>\n",
       "      <td>1.104943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.086709</td>\n",
       "      <td>1.047103</td>\n",
       "      <td>1.022782</td>\n",
       "      <td>19.670918</td>\n",
       "      <td>0.806505</td>\n",
       "      <td>0.065827</td>\n",
       "      <td>7.851000</td>\n",
       "      <td>0.921226</td>\n",
       "      <td>-0.014895</td>\n",
       "      <td>-0.023149</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009781</td>\n",
       "      <td>0.969639</td>\n",
       "      <td>0.000792</td>\n",
       "      <td>-0.019421</td>\n",
       "      <td>-0.066347</td>\n",
       "      <td>-0.073329</td>\n",
       "      <td>1.073442</td>\n",
       "      <td>1.061139</td>\n",
       "      <td>0.008524</td>\n",
       "      <td>0.060689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>0.952774</td>\n",
       "      <td>0.820870</td>\n",
       "      <td>1.023659</td>\n",
       "      <td>26.797144</td>\n",
       "      <td>-0.092427</td>\n",
       "      <td>4.615633</td>\n",
       "      <td>6.082351</td>\n",
       "      <td>0.897115</td>\n",
       "      <td>0.843766</td>\n",
       "      <td>1.062096</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.010419</td>\n",
       "      <td>-0.008431</td>\n",
       "      <td>1.009220</td>\n",
       "      <td>-0.020458</td>\n",
       "      <td>0.976878</td>\n",
       "      <td>-0.099069</td>\n",
       "      <td>0.991255</td>\n",
       "      <td>1.057259</td>\n",
       "      <td>0.046726</td>\n",
       "      <td>0.081935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>1.025562</td>\n",
       "      <td>0.683903</td>\n",
       "      <td>0.148759</td>\n",
       "      <td>23.072406</td>\n",
       "      <td>-0.112876</td>\n",
       "      <td>0.841941</td>\n",
       "      <td>-1.496806</td>\n",
       "      <td>0.966524</td>\n",
       "      <td>0.624451</td>\n",
       "      <td>1.057840</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014569</td>\n",
       "      <td>-0.020873</td>\n",
       "      <td>0.053306</td>\n",
       "      <td>0.008983</td>\n",
       "      <td>1.008041</td>\n",
       "      <td>-0.041440</td>\n",
       "      <td>0.944608</td>\n",
       "      <td>0.005733</td>\n",
       "      <td>0.015435</td>\n",
       "      <td>0.971664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>-0.017521</td>\n",
       "      <td>2.971828</td>\n",
       "      <td>0.065092</td>\n",
       "      <td>20.669503</td>\n",
       "      <td>2.625256</td>\n",
       "      <td>5.984285</td>\n",
       "      <td>347.287242</td>\n",
       "      <td>-0.067533</td>\n",
       "      <td>-0.025066</td>\n",
       "      <td>1.071818</td>\n",
       "      <td>...</td>\n",
       "      <td>1.007326</td>\n",
       "      <td>-0.110520</td>\n",
       "      <td>-0.023948</td>\n",
       "      <td>0.020534</td>\n",
       "      <td>0.121246</td>\n",
       "      <td>0.028778</td>\n",
       "      <td>0.055800</td>\n",
       "      <td>-0.010000</td>\n",
       "      <td>-0.051961</td>\n",
       "      <td>0.091571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>1.080764</td>\n",
       "      <td>0.863658</td>\n",
       "      <td>0.928797</td>\n",
       "      <td>21.933438</td>\n",
       "      <td>0.770049</td>\n",
       "      <td>4.145770</td>\n",
       "      <td>17.517423</td>\n",
       "      <td>0.965627</td>\n",
       "      <td>-0.012321</td>\n",
       "      <td>1.024681</td>\n",
       "      <td>...</td>\n",
       "      <td>0.606789</td>\n",
       "      <td>0.975313</td>\n",
       "      <td>-0.054702</td>\n",
       "      <td>0.006308</td>\n",
       "      <td>0.012312</td>\n",
       "      <td>0.015555</td>\n",
       "      <td>1.004909</td>\n",
       "      <td>-0.038201</td>\n",
       "      <td>0.938499</td>\n",
       "      <td>1.088596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0.001406</td>\n",
       "      <td>1.813765</td>\n",
       "      <td>0.102778</td>\n",
       "      <td>17.663608</td>\n",
       "      <td>3.020929</td>\n",
       "      <td>-0.023534</td>\n",
       "      <td>2.486119</td>\n",
       "      <td>0.990466</td>\n",
       "      <td>-0.019897</td>\n",
       "      <td>1.008663</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005349</td>\n",
       "      <td>1.005562</td>\n",
       "      <td>0.013043</td>\n",
       "      <td>0.020334</td>\n",
       "      <td>-0.117685</td>\n",
       "      <td>0.873942</td>\n",
       "      <td>0.983274</td>\n",
       "      <td>-0.024163</td>\n",
       "      <td>0.040920</td>\n",
       "      <td>0.997124</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     survived    pclass       sex        age     sibsp     parch        fare  \\\n",
       "0    1.080237  0.791131  1.063448  28.413202  0.771792 -0.021365   34.495780   \n",
       "1    0.917577  2.145518  1.065295  19.750091  2.596427 -0.150105   91.814781   \n",
       "2    0.855402  3.106432 -0.123146  20.296845  3.790539  0.800693    7.423602   \n",
       "3    1.012989  1.833180  1.018224  33.280963 -0.145543  0.068389    7.426653   \n",
       "4    0.086709  1.047103  1.022782  19.670918  0.806505  0.065827    7.851000   \n",
       "..        ...       ...       ...        ...       ...       ...         ...   \n",
       "995  0.952774  0.820870  1.023659  26.797144 -0.092427  4.615633    6.082351   \n",
       "996  1.025562  0.683903  0.148759  23.072406 -0.112876  0.841941   -1.496806   \n",
       "997 -0.017521  2.971828  0.065092  20.669503  2.625256  5.984285  347.287242   \n",
       "998  1.080764  0.863658  0.928797  21.933438  0.770049  4.145770   17.517423   \n",
       "999  0.001406  1.813765  0.102778  17.663608  3.020929 -0.023534    2.486119   \n",
       "\n",
       "        alone  who_child   who_man  ...  embark_town_Queenstown  \\\n",
       "0    1.035639  -0.023513  1.014079  ...                0.013898   \n",
       "1    0.891793   0.026567  1.029313  ...                0.004099   \n",
       "2    0.947184   0.775650  1.025470  ...                0.009357   \n",
       "3   -0.132893  -0.024482  0.983342  ...                0.008880   \n",
       "4    0.921226  -0.014895 -0.023149  ...               -0.009781   \n",
       "..        ...        ...       ...  ...                     ...   \n",
       "995  0.897115   0.843766  1.062096  ...               -0.010419   \n",
       "996  0.966524   0.624451  1.057840  ...                0.014569   \n",
       "997 -0.067533  -0.025066  1.071818  ...                1.007326   \n",
       "998  0.965627  -0.012321  1.024681  ...                0.606789   \n",
       "999  0.990466  -0.019897  1.008663  ...                0.005349   \n",
       "\n",
       "     embark_town_Southampton  embarked_C  embarked_Q  embarked_S  \\\n",
       "0                   0.145945    0.935486    0.028479   -0.073765   \n",
       "1                   0.930086   -0.006607    0.998861    0.968039   \n",
       "2                   0.931154   -0.045928    1.174743    0.980231   \n",
       "3                   1.037112   -0.056452   -0.008572    0.041343   \n",
       "4                   0.969639    0.000792   -0.019421   -0.066347   \n",
       "..                       ...         ...         ...         ...   \n",
       "995                -0.008431    1.009220   -0.020458    0.976878   \n",
       "996                -0.020873    0.053306    0.008983    1.008041   \n",
       "997                -0.110520   -0.023948    0.020534    0.121246   \n",
       "998                 0.975313   -0.054702    0.006308    0.012312   \n",
       "999                 1.005562    0.013043    0.020334   -0.117685   \n",
       "\n",
       "     adult_male_False  adult_male_True  class_First  class_Second  class_Third  \n",
       "0           -0.120157         0.918098     0.867076     -0.033363     1.104807  \n",
       "1           -0.073928         0.999255     0.000214      0.062596     1.018597  \n",
       "2            1.004876        -0.096677    -0.038539      0.048083     0.020445  \n",
       "3           -0.073893        -0.048799     0.772480      0.057497     1.104943  \n",
       "4           -0.073329         1.073442     1.061139      0.008524     0.060689  \n",
       "..                ...              ...          ...           ...          ...  \n",
       "995         -0.099069         0.991255     1.057259      0.046726     0.081935  \n",
       "996         -0.041440         0.944608     0.005733      0.015435     0.971664  \n",
       "997          0.028778         0.055800    -0.010000     -0.051961     0.091571  \n",
       "998          0.015555         1.004909    -0.038201      0.938499     1.088596  \n",
       "999          0.873942         0.983274    -0.024163      0.040920     0.997124  \n",
       "\n",
       "[1000 rows x 22 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample data similar to training data.\n",
    "fake_samples = ctgan.sample(n=1000, \n",
    "             condition_column=None, \n",
    "             condition_value=None)\n",
    "\n",
    "pd.DataFrame(data=fake_samples, columns=col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU for cloud training\n",
    "if torch.cuda.is_available(): \n",
    "    device = torch.device(\"cuda\") # device = GPU\n",
    "else:\n",
    "    device = torch.device(\"cpu\") # device = CPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "\n",
    "# =======================================\n",
    "# Section commented out until next meeting\n",
    "# =======================================\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.fc1 = nn.Linear(n_features, H_0)\n",
    "        self.fc2 = nn.Linear(H_0, H_1)\n",
    "        self.fc3 = nn.Linear(H_1, D_out)\n",
    "        \n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "        \n",
    "    def forward(self, z):\n",
    "        z = F.leaky_relu(self.fc1(z))\n",
    "        z = F.leaky_relu(self.fc2(z)) \n",
    "        z = F.leaky_relu(self.fc3(z))\n",
    "        return z\n",
    "\n",
    "    \n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.fc1 = nn.Linear(n_features, H_0)\n",
    "        self.fc2 = nn.Linear(H_0, H_1)\n",
    "        self.fc3 = nn.Linear(H_1, D_out)\n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(self.fc1(x))\n",
    "#          x = self.dropout()\n",
    "        x = F.leaky_relu(self.fc2(x)) \n",
    "        x = F.leaky_relu(self.fc3(x))\n",
    "        return x\n",
    "\n",
    "class Toy_Dataset(Dataset): # inherit from torch's Dataset class.\n",
    "    def __init__(self, train):\n",
    "        # data loading\n",
    "        if train == True:\n",
    "            self.X = torch.from_numpy(X_train.astype(np.float32))\n",
    "            self.Y = torch.from_numpy(Y_train.astype(np.float32))\n",
    "        else:\n",
    "            self.X = torch.from_numpy(X_test.astype(np.float32))\n",
    "            self.Y = torch.from_numpy(Y_test.astype(np.float32))\n",
    "\n",
    "        if self.X.shape[0] == self.Y.shape[0]:\n",
    "            self.n_samples = self.X.shape[0]\n",
    "        else:\n",
    "            raise ValueError(\"Shape mismatch\")\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.Y[idx]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "        # len(dataset)\n",
    "\n",
    "# Initialize constants\n",
    "n_features = X_train.shape[1]\n",
    "BATCH_SIZE, D_in, D_out = 15, n_features, 1\n",
    "H_0, H_1 = int(0.7*n_features), int(0.4*n_features)\n",
    "\n",
    "# Set DataLoaders    \n",
    "train_set = Toy_Dataset(train=True)\n",
    "test_set = Toy_Dataset(train=False)\n",
    "train_dl = DataLoader(dataset=train_set, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_dl = DataLoader(dataset=test_set, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "# Initialize networks\n",
    "G = Generator()\n",
    "D = Discriminator()\n",
    "\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "\n",
    "def check_models():\n",
    "    x = torch.from_numpy(X_train[0]).float() \n",
    "    print( G(x) )\n",
    "    print( D(x) )\n",
    "    \n",
    "check_models()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References (GANs)\n",
    "\n",
    "Conceptual References:\n",
    "- [*GANS*, Google Developers](https://developers.google.com/machine-learning/gan/gan_structure)\n",
    "- [Ian Goodfellow on Lex Fridman podcast](https://www.youtube.com/watch?v=Z6rxFNMGdn0&t=2826s&ab_channel=LexFridman)\n",
    "- [Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., ... & Bengio, Y. (2014). Generative adversarial nets. In *Advances in neural information processing systems* (pp. 2672-2680).](https://arxiv.org/pdf/1406.2661.pdf)\n",
    "- [Salimans, T., Goodfellow, I., Zaremba, W., Cheung, V., Radford, A., & Chen, X. (2016). Improved techniques for training gans. In *Advances in neural information processing systems* (pp. 2234-2242).](https://arxiv.org/pdf/1606.03498.pdf)\n",
    "- [DeepInsight: A methodology to transform a non-image data to an image for convolution neural network architecture](https://www.nature.com/articles/s41598-019-47765-6)\n",
    "\n",
    "Implementation References:\n",
    "- [eriklindernoren/PyTorch-GAN](https://github.com/eriklindernoren/PyTorch-GAN/blob/master/implementations/gan/gan.py)\n",
    "  - [list of successful GAN architectures](https://github.com/eriklindernoren/PyTorch-GAN#gan)\n",
    "- [fast ai, free GPU w/ Google Colab guide](https://www.kdnuggets.com/2018/02/fast-ai-lesson-1-google-colab-free-gpu.html)\n",
    "- [PyTorch GAN, github.com/devnag](https://github.com/devnag/pytorch-generative-adversarial-networks/blob/master/gan_pytorch.py)\n",
    "- [Brownlee, Jason (2020). How to Code the GAN Training Algorithm. *machinelearningmastery.com*](https://machinelearningmastery.com/how-to-code-the-generative-adversarial-network-training-algorithm-and-loss-functions/)\n",
    "- TGAN: [paper](https://arxiv.org/pdf/1811.11264.pdf), [repo](https://github.com/sdv-dev/TGAN)\n",
    "- CTGAN: [repo](https://github.com/sdv-dev/CTGAN)\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next steps\n",
    "\n",
    "\n",
    "**Fun stuff to try**:\n",
    "- .\n",
    "- . \n",
    "- .\n",
    "\n",
    "## TODO\n",
    "- Play around with the CTGAN architecture to improve upon it\n",
    "- Email Itsik to get approval to work with the actual dataset.\n",
    "- Plan out a hyperparameter optimization scheme for the disease predicting NNs.\n",
    "- Implement the NNs for image representation of the genome.\n",
    "  - Set up Convolutional NN architecture to analyze the images\n",
    "- Compare everything empirically in a disease prediction task. Linear methods, MLP + GAN, image representation + CNN, XGBoost (benchmark)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ds_env)",
   "language": "python",
   "name": "ds_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
