{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GANs with non image data \n",
    "\n",
    "\n",
    "- [Robin Ricard's GAN for sinusoid modeling (keras)](http://www.rricard.me/machine/learning/generative/adversarial/networks/keras/tensorflow/2017/04/05/gans-part2.html)\n",
    "- [A methodology to transform non-image data to an image for convolution NN architecture](https://www.nature.com/articles/s41598-019-47765-6)\n",
    "- [reddit: GAN w/ non image data](https://www.reddit.com/r/MachineLearning/comments/7ac6xx/d_gan_with_non_image_data/)\n",
    "- Real-values (medical) time series generation w/ recurrent conditional GANs - [[paper]](https://arxiv.org/pdf/1706.02633.pdf), [[code]](https://github.com/ratschlab/RGAN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# from keras.models import Model\n",
    "# from keras.layers import Input, Reshape\n",
    "\n",
    "# \"core\" layers in Keras are those used in almost every NN\n",
    "from keras.layers.core import Dense, Activation, Dropout, Flatten\n",
    "# synonymous to tf.keras.layers:\n",
    "# from keras.layers import Dense, Activation, Dropout, Flatten\n",
    "\n",
    "\n",
    "# from keras.layers.normalization import BatchNormalization\n",
    "# from keras.layers.convolutional import UpSampling1D, Conv1D\n",
    "# from keras.layers.advanced_activations import LeakyReLU\n",
    "# import keras.optimizers as optim\n",
    "# from keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 10)]              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 200)               2200      \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 50)                10050     \n",
      "=================================================================\n",
      "Total params: 12,250\n",
      "Trainable params: 12,250\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def get_generative(G_in, dense_dim=200, out_dim=50, lr=1e-3):\n",
    "    x = keras.layers.Dense(dense_dim)(G_in)\n",
    "    x = keras.layers.Activation('tanh')(x)\n",
    "    G_out = Dense(out_dim, activation='tanh')(x)\n",
    "    G = keras.models.Model(G_in, G_out)\n",
    "    optimizer = keras.optimizers.SGD(lr=lr)\n",
    "    G.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "    return G, G_out\n",
    "\n",
    "G_in = keras.layers.Input(shape=[10])\n",
    "G, G_out = get_generative(G_in)\n",
    "G.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tf.float32"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G_out.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 50])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Operation 'dense_1/Tanh' type=Tanh>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G_out.op"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "PyTorch GAN Tutorial, DCGAN: https://youtu.be/5RYETbFFQ7s?t=393"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorFlow Notes\n",
    "\n",
    "#### `keras.layers.Dense` (class): \n",
    "- A  densely-connected NN layer. Synounymous to fully-connected layer in torch. Performs a linear operation on the layerâ€™s input vector, `output = activation(dot(input, kernel) + bias)`\n",
    "\n",
    "#### `keras.models.Model` (class):\n",
    "- Groups layers into an object with training and inference features. \n",
    "- Args:\n",
    "  - `inputs`: The input(s) of the model: a `keras.Input` object or list of `keras.Input` objects.\n",
    "  - `outputs`: The output(s) of the model. See Functional API example below.\n",
    "  - `name`: String, the name of the model.\n",
    "- If `model = keras.models.Model(...)`, you can use `model.compile()` to config the model with losses and metrics,\n",
    "`model.fit()` to train, and `model.predict()` to make predictions.\n",
    "\n",
    "#### `keras.layers.Activation`\n",
    "- Applies an activation function to an output.\n",
    "- Arguments:\n",
    "  - activation: Activation function, such as `tf.nn.relu`, or string name of built-in activation function, such as \"relu\".\n",
    "- Usage:\n",
    "```python\n",
    ">>> layer = tf.keras.layers.Activation('relu')\n",
    ">>> output = layer([-3.0, -1.0, 0.0, 2.0])\n",
    ">>> list(output.numpy())\n",
    "[0.0, 0.0, 0.0, 2.0]\n",
    ">>> layer = tf.keras.layers.Activation(tf.nn.relu)\n",
    ">>> output = layer([-3.0, -1.0, 0.0, 2.0])\n",
    ">>> list(output.numpy())\n",
    "[0.0, 0.0, 0.0, 2.0]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ds_env)",
   "language": "python",
   "name": "ds_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
