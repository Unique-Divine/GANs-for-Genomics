{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import PyTorch\n",
    "import torch\n",
    "\n",
    "# standard DS stack\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "import pandas as pd\n",
    "# embed static images in the ipynb\n",
    "%matplotlib inline \n",
    "\n",
    "# neural network package\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "\n",
    "# computer vision\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "# dataset loading\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# convenient package for plotting loss functions\n",
    "# from livelossplot import PlotLosses\n",
    "\n",
    "import copy\n",
    "import importlib.util # to run outside module\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve preprocessed titanic dataset\n",
    "system_path = r\"C:\\Users\\uniqu\\Adaptation\\github repos\" \\\n",
    "              + \"\\Bioinformatics-Neural Networks for Genomic Risk\"\n",
    "\n",
    "exec(open(system_path+\"\\preprocess_titanic.py\").read())\n",
    "\n",
    "X, Y = preprocess_titanic()\n",
    "\n",
    "# Perform train-test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    X, Y, test_size=0.3, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature names:\n",
      "  ['pclass', 'sex', 'age', 'sibsp', 'parch', 'fare', 'embarked', 'class', 'who', 'adult_male', 'embark_town', 'alone']\n",
      "\n",
      "target names: 'survived'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([ 3.  ,  1.  , 22.  ,  1.  ,  0.  ,  7.25,  0.  ,  0.  ,  1.  ,\n",
       "         0.  ,  0.  ,  0.  ,  1.  ,  0.  ,  0.  ,  1.  ,  0.  ,  1.  ,\n",
       "         0.  ,  0.  ,  1.  ]),\n",
       " array([0.]))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Real dataset\n",
    "real_data = np.hstack([X, Y])\n",
    "real_data.shape\n",
    "print(f\"feature names:\\n  {list(titanic_data.columns[1:])}\\n\")\n",
    "print(f\"target names: '{titanic_data.columns[0]}'\")\n",
    "X[0], Y[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CTGAN\n",
    "\n",
    "[TGAN](https://github.com/sdv-dev/TGAN) seemed like the exact tool I was looking for. It turns out [CTGAN](https://github.com/sdv-dev/CTGAN) is better. Several major differences make CTGAN outperform TGAN.\n",
    "- **Preprocessing**: CTGAN uses more sophisticated Variational Gaussian Mixture Model to detect modes of continuous columns.\n",
    "- **Network structure**: TGAN uses LSTM to generate synthetic data column by column. CTGAN uses Fully-connected networks which is more efficient.\n",
    "- **Features to prevent** mode collapse: We design a conditional generator and resample the training data to prevent model collapse on discrete columns. We use WGANGP and PacGAN to stabilize the training of GAN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install ctgan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'ctgan'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-43ca99b3701f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mctgan\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mload_demo\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_demo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mctgan\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCTGANSynthesizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mctgan\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCTGANSynthesizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'ctgan'"
     ]
    }
   ],
   "source": [
    "from ctgan import load_demo\n",
    "data = load_demo()\n",
    "\n",
    "from ctgan import CTGANSynthesizer\n",
    "ctgan = CTGANSynthesizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.0076], grad_fn=<LeakyReluBackward0>)\n",
      "tensor([-0.0026], grad_fn=<LeakyReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# GPU for cloud training\n",
    "if torch.cuda.is_available(): \n",
    "    device = torch.device(\"cuda\") # device = GPU\n",
    "else:\n",
    "    device = torch.device(\"cpu\") # device = CPU\n",
    "    \n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.fc1 = nn.Linear(n_features, H_0)\n",
    "        self.fc2 = nn.Linear(H_0, H_1)\n",
    "        self.fc3 = nn.Linear(H_1, D_out)\n",
    "        \n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "        \n",
    "    def forward(self, z):\n",
    "        z = F.leaky_relu(self.fc1(z))\n",
    "        z = F.leaky_relu(self.fc2(z)) \n",
    "        z = F.leaky_relu(self.fc3(z))\n",
    "        return z\n",
    "\n",
    "    \n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.fc1 = nn.Linear(n_features, H_0)\n",
    "        self.fc2 = nn.Linear(H_0, H_1)\n",
    "        self.fc3 = nn.Linear(H_1, D_out)\n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(self.fc1(x))\n",
    "#          x = self.dropout()\n",
    "        x = F.leaky_relu(self.fc2(x)) \n",
    "        x = F.leaky_relu(self.fc3(x))\n",
    "        return x\n",
    "\n",
    "class Toy_Dataset(Dataset): # inherit from torch's Dataset class.\n",
    "    def __init__(self, train):\n",
    "        # data loading\n",
    "        if train == True:\n",
    "            self.X = torch.from_numpy(X_train.astype(np.float32))\n",
    "            self.Y = torch.from_numpy(Y_train.astype(np.float32))\n",
    "        else:\n",
    "            self.X = torch.from_numpy(X_test.astype(np.float32))\n",
    "            self.Y = torch.from_numpy(Y_test.astype(np.float32))\n",
    "\n",
    "        if self.X.shape[0] == self.Y.shape[0]:\n",
    "            self.n_samples = self.X.shape[0]\n",
    "        else:\n",
    "            raise ValueError(\"Shape mismatch\")\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.Y[idx]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "        # len(dataset)\n",
    "\n",
    "# Initialize constants\n",
    "n_features = X_train.shape[1]\n",
    "BATCH_SIZE, D_in, D_out = 15, n_features, 1\n",
    "H_0, H_1 = int(0.7*n_features), int(0.4*n_features)\n",
    "\n",
    "# Set DataLoaders    \n",
    "train_set = Toy_Dataset(train=True)\n",
    "test_set = Toy_Dataset(train=False)\n",
    "train_dl = DataLoader(dataset=train_set, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_dl = DataLoader(dataset=test_set, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "# Initialize networks\n",
    "G = Generator()\n",
    "D = Discriminator()\n",
    "\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "\n",
    "def check_models():\n",
    "    x = torch.from_numpy(X_train[0]).float() \n",
    "    print( G(x) )\n",
    "    print( D(x) )\n",
    "    \n",
    "check_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "Conceptual References:\n",
    "- [*GANS*, Google Developers](https://developers.google.com/machine-learning/gan/gan_structure)\n",
    "- [Ian Goodfellow on Lex Fridman podcast](https://www.youtube.com/watch?v=Z6rxFNMGdn0&t=2826s&ab_channel=LexFridman)\n",
    "- [Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., ... & Bengio, Y. (2014). Generative adversarial nets. In *Advances in neural information processing systems* (pp. 2672-2680).](https://arxiv.org/pdf/1406.2661.pdf)\n",
    "- [Salimans, T., Goodfellow, I., Zaremba, W., Cheung, V., Radford, A., & Chen, X. (2016). Improved techniques for training gans. In *Advances in neural information processing systems* (pp. 2234-2242).](https://arxiv.org/pdf/1606.03498.pdf)\n",
    "- [DeepInsight: A methodology to transform a non-image data to an image for convolution neural network architecture](https://www.nature.com/articles/s41598-019-47765-6)\n",
    "\n",
    "Implementation References:\n",
    "- [eriklindernoren/PyTorch-GAN](https://github.com/eriklindernoren/PyTorch-GAN/blob/master/implementations/gan/gan.py)\n",
    "  - [list of successful GAN architectures](https://github.com/eriklindernoren/PyTorch-GAN#gan)\n",
    "- [fast ai, free GPU w/ Google Colab guide](https://www.kdnuggets.com/2018/02/fast-ai-lesson-1-google-colab-free-gpu.html)\n",
    "- [PyTorch GAN, github.com/devnag](https://github.com/devnag/pytorch-generative-adversarial-networks/blob/master/gan_pytorch.py)\n",
    "- [Brownlee, Jason (2020). How to Code the GAN Training Algorithm. *machinelearningmastery.com*](https://machinelearningmastery.com/how-to-code-the-generative-adversarial-network-training-algorithm-and-loss-functions/)\n",
    "- TGAN: [paper](https://arxiv.org/pdf/1811.11264.pdf), [repo](https://github.com/sdv-dev/TGAN)\n",
    "- CTGAN: [repo](https://github.com/sdv-dev/CTGAN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.19.1'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ds_env)",
   "language": "python",
   "name": "ds_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
