{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#CTGAN\" data-toc-modified-id=\"CTGAN-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>CTGAN</a></span><ul class=\"toc-item\"><li><span><a href=\"#Generate-sythetic-data\" data-toc-modified-id=\"Generate-sythetic-data-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Generate sythetic data</a></span></li></ul></li><li><span><a href=\"#References\" data-toc-modified-id=\"References-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>References</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import PyTorch\n",
    "import torch\n",
    "\n",
    "# standard DS stack\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "import pandas as pd\n",
    "# embed static images in the ipynb\n",
    "%matplotlib inline \n",
    "\n",
    "# neural network package\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "\n",
    "# computer vision\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "# dataset loading\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# convenient package for plotting loss functions\n",
    "# from livelossplot import PlotLosses\n",
    "\n",
    "import copy\n",
    "import importlib.util # to run outside module\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve preprocessed titanic dataset\n",
    "system_path = r\"C:\\Users\\uniqu\\Adaptation\\github repos\" \\\n",
    "              + \"\\Bioinformatics-Neural Networks for Genomic Risk\"\n",
    "\n",
    "exec(open(system_path+\"\\preprocess_titanic.py\").read())\n",
    "\n",
    "X, Y, col_names = preprocess_titanic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature names:\n",
      "  ['pclass', 'sex', 'age', 'sibsp', 'parch', 'fare', 'embarked', 'class', 'who', 'adult_male', 'embark_town', 'alone']\n",
      "\n",
      "target names: 'survived'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([ 3.  ,  1.  , 22.  ,  1.  ,  0.  ,  7.25,  0.  ,  0.  ,  1.  ,\n",
       "         0.  ,  0.  ,  0.  ,  1.  ,  0.  ,  0.  ,  1.  ,  0.  ,  1.  ,\n",
       "         0.  ,  0.  ,  1.  ]),\n",
       " array([0.]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Real (toy) dataset\n",
    "def get_real_data(X, Y, dataset):\n",
    "    \"\"\"[summary]\n",
    "\n",
    "    Args:\n",
    "        X (np.ndarray): Feature Matrix.\n",
    "        Y (np.ndarray): Target Matrix.\n",
    "\n",
    "    Returns:\n",
    "        [type]: [description]\n",
    "    \"\"\"\n",
    "    # feature_names = list(dataset.columns)[1:]\n",
    "    # target_names = list(dataset.columns)[0]\n",
    "    \n",
    "    # Perform train-test split\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "        X, Y, test_size=0.3, random_state=7)\n",
    "\n",
    "    real_data = np.hstack([Y, X])\n",
    "    train_data = np.hstack([Y_train, X_train])\n",
    "    test_data = np.hstack([Y_test, X_test])\n",
    "        \n",
    "    return real_data, train_data, test_data\n",
    "\n",
    "real_data, train_data, test_data = get_real_data(X, Y, titanic_data)\n",
    "\n",
    "print(f\"feature names:\\n  {list(titanic_data.columns[1:])}\\n\")\n",
    "print(f\"target names: '{titanic_data.columns[0]}'\")\n",
    "X[0], Y[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CTGAN\n",
    "\n",
    "[TGAN](https://github.com/sdv-dev/TGAN) seemed like the exact tool I was looking for. It turns out [CTGAN](https://github.com/sdv-dev/CTGAN) is better. Several major differences make CTGAN outperform TGAN.\n",
    "- **Preprocessing**: CTGAN uses more sophisticated Variational Gaussian Mixture Model to detect modes of continuous columns.\n",
    "- **Network structure**: TGAN uses LSTM to generate synthetic data column by column. CTGAN uses Fully-connected networks which is more efficient.\n",
    "- **Features to prevent** mode collapse: We design a conditional generator and resample the training data to prevent model collapse on discrete columns. We use WGANGP and PacGAN to stabilize the training of GAN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from ctgan import load_demo\n",
    "data = load_demo()\n",
    "\n",
    "from ctgan import CTGANSynthesizer\n",
    "ctgan = CTGANSynthesizer()\n",
    "\n",
    "# CTGAN Synthesizer models: G & D\n",
    "# Fit the models to the training data\n",
    "ctgan.fit(train_data=train_data,\n",
    "          epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate sythetic data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample data similar to training data.\n",
    "fake_samples = ctgan.sample(n=1000, \n",
    "             condition_column=None, \n",
    "             condition_value=None)\n",
    "\n",
    "pd.DataFrame(data=fake_samples, columns=col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU for cloud training\n",
    "if torch.cuda.is_available(): \n",
    "    device = torch.device(\"cuda\") # device = GPU\n",
    "else:\n",
    "    device = torch.device(\"cpu\") # device = CPU\n",
    "    \n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.fc1 = nn.Linear(n_features, H_0)\n",
    "        self.fc2 = nn.Linear(H_0, H_1)\n",
    "        self.fc3 = nn.Linear(H_1, D_out)\n",
    "        \n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "        \n",
    "    def forward(self, z):\n",
    "        z = F.leaky_relu(self.fc1(z))\n",
    "        z = F.leaky_relu(self.fc2(z)) \n",
    "        z = F.leaky_relu(self.fc3(z))\n",
    "        return z\n",
    "\n",
    "    \n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.fc1 = nn.Linear(n_features, H_0)\n",
    "        self.fc2 = nn.Linear(H_0, H_1)\n",
    "        self.fc3 = nn.Linear(H_1, D_out)\n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(self.fc1(x))\n",
    "#          x = self.dropout()\n",
    "        x = F.leaky_relu(self.fc2(x)) \n",
    "        x = F.leaky_relu(self.fc3(x))\n",
    "        return x\n",
    "\n",
    "class Toy_Dataset(Dataset): # inherit from torch's Dataset class.\n",
    "    def __init__(self, train):\n",
    "        # data loading\n",
    "        if train == True:\n",
    "            self.X = torch.from_numpy(X_train.astype(np.float32))\n",
    "            self.Y = torch.from_numpy(Y_train.astype(np.float32))\n",
    "        else:\n",
    "            self.X = torch.from_numpy(X_test.astype(np.float32))\n",
    "            self.Y = torch.from_numpy(Y_test.astype(np.float32))\n",
    "\n",
    "        if self.X.shape[0] == self.Y.shape[0]:\n",
    "            self.n_samples = self.X.shape[0]\n",
    "        else:\n",
    "            raise ValueError(\"Shape mismatch\")\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.Y[idx]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "        # len(dataset)\n",
    "\n",
    "# Initialize constants\n",
    "n_features = X_train.shape[1]\n",
    "BATCH_SIZE, D_in, D_out = 15, n_features, 1\n",
    "H_0, H_1 = int(0.7*n_features), int(0.4*n_features)\n",
    "\n",
    "# Set DataLoaders    \n",
    "train_set = Toy_Dataset(train=True)\n",
    "test_set = Toy_Dataset(train=False)\n",
    "train_dl = DataLoader(dataset=train_set, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_dl = DataLoader(dataset=test_set, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "# Initialize networks\n",
    "G = Generator()\n",
    "D = Discriminator()\n",
    "\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "\n",
    "def check_models():\n",
    "    x = torch.from_numpy(X_train[0]).float() \n",
    "    print( G(x) )\n",
    "    print( D(x) )\n",
    "    \n",
    "check_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "Conceptual References:\n",
    "- [*GANS*, Google Developers](https://developers.google.com/machine-learning/gan/gan_structure)\n",
    "- [Ian Goodfellow on Lex Fridman podcast](https://www.youtube.com/watch?v=Z6rxFNMGdn0&t=2826s&ab_channel=LexFridman)\n",
    "- [Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., ... & Bengio, Y. (2014). Generative adversarial nets. In *Advances in neural information processing systems* (pp. 2672-2680).](https://arxiv.org/pdf/1406.2661.pdf)\n",
    "- [Salimans, T., Goodfellow, I., Zaremba, W., Cheung, V., Radford, A., & Chen, X. (2016). Improved techniques for training gans. In *Advances in neural information processing systems* (pp. 2234-2242).](https://arxiv.org/pdf/1606.03498.pdf)\n",
    "- [DeepInsight: A methodology to transform a non-image data to an image for convolution neural network architecture](https://www.nature.com/articles/s41598-019-47765-6)\n",
    "\n",
    "Implementation References:\n",
    "- [eriklindernoren/PyTorch-GAN](https://github.com/eriklindernoren/PyTorch-GAN/blob/master/implementations/gan/gan.py)\n",
    "  - [list of successful GAN architectures](https://github.com/eriklindernoren/PyTorch-GAN#gan)\n",
    "- [fast ai, free GPU w/ Google Colab guide](https://www.kdnuggets.com/2018/02/fast-ai-lesson-1-google-colab-free-gpu.html)\n",
    "- [PyTorch GAN, github.com/devnag](https://github.com/devnag/pytorch-generative-adversarial-networks/blob/master/gan_pytorch.py)\n",
    "- [Brownlee, Jason (2020). How to Code the GAN Training Algorithm. *machinelearningmastery.com*](https://machinelearningmastery.com/how-to-code-the-generative-adversarial-network-training-algorithm-and-loss-functions/)\n",
    "- TGAN: [paper](https://arxiv.org/pdf/1811.11264.pdf), [repo](https://github.com/sdv-dev/TGAN)\n",
    "- CTGAN: [repo](https://github.com/sdv-dev/CTGAN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ds_env)",
   "language": "python",
   "name": "ds_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
