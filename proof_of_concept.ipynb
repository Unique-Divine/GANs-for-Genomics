{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import PyTorch\n",
    "import torch\n",
    "\n",
    "# standard DS stack\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "import pandas as pd\n",
    "# embed static images in the ipynb\n",
    "%matplotlib inline \n",
    "\n",
    "# neural network package\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "\n",
    "# computer vision\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "# dataset loading\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# convenient package for plotting loss functions\n",
    "# from livelossplot import PlotLosses\n",
    "\n",
    "import copy\n",
    "# import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "genos_only.shape: (5000, 100)\n",
      "phenos_only.shape: (5000,)\n",
      "genos_plus.shape: (500, 100)\n",
      "exprs_plus.shape: (500, 10)\n",
      "phenos_plus.shape: (500,)\n",
      "beta0.shape (100, 10)\n",
      "beta1.shape (10,)\n",
      "beta2.shape (100,)\n"
     ]
    }
   ],
   "source": [
    "# Run script for simulated data\n",
    "import importlib.util\n",
    "def get_path(sys, local):\n",
    "    system_path = sys\n",
    "    local_path = local \n",
    "    path = system_path + local_path\n",
    "    return path\n",
    "\n",
    "path = get_path(sys=r\"C:\\Users\\uniqu\\Adaptation\\github repos\"\n",
    "                    + \"\\Bioinformatics-Neural Networks for Genomic Risk\",\n",
    "                local=\"\\simulate_twas.py\")\n",
    "exec(open(path).read())\n",
    "(beta1, beta2, beta3) = (beta for beta in betas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "genos_only.shape: (5000, 100)\n",
      "phenos_only.shape: (5000, 1)\n",
      "genos_plus.shape: (500, 100)\n",
      "exprs_plus.shape: (500, 10)\n",
      "phenos_plus.shape: (500, 1)\n",
      "beta0.shape (1000, 1)\n",
      "beta1.shape (10, 1)\n",
      "beta2.shape (100, 1)\n"
     ]
    }
   ],
   "source": [
    "# turn 1D arrays to column vectors\n",
    "variables = [genos_only, phenos_only, genos_plus, exprs_plus, phenos_plus]\n",
    "\n",
    "for idx, var in enumerate(variables):\n",
    "    if var.ndim == 1:\n",
    "        variables[idx] = np.reshape(variables[idx], newshape=(-1,1))\n",
    "[genos_only, phenos_only, genos_plus, exprs_plus, phenos_plus] = variables\n",
    "\n",
    "betas = list(betas)\n",
    "for idx, beta in enumerate(betas):\n",
    "    if var.ndim == 1:\n",
    "        betas[idx] = np.reshape(betas[idx], newshape=(-1,1))\n",
    "\n",
    "print_shapes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform train-test split\n",
    "X, Y = genos_only, phenos_only\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3,\n",
    "                                                    random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60, 100]) torch.Size([60, 1])\n",
      "Shape of single feature: torch.Size([100])\n",
      "Shape of single target: torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "class simulated_Dataset(Dataset): # inherit from torch's Dataset class.\n",
    "    def __init__(self, train):\n",
    "        # data loading\n",
    "        if train == True:\n",
    "            self.X = torch.from_numpy(X_train.astype(np.float32))\n",
    "            self.Y = torch.from_numpy(Y_train.astype(np.float32))\n",
    "        else:\n",
    "            self.X = torch.from_numpy(X_test.astype(np.float32))\n",
    "            self.Y = torch.from_numpy(Y_test.reshape(-1,1).astype(np.float32))\n",
    "\n",
    "        if self.X.shape[0] == self.Y.shape[0]:\n",
    "            self.n_samples = self.X.shape[0]\n",
    "        else:\n",
    "            raise ValueError(\"Shape mismatch\")\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.Y[idx]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "\n",
    "BATCH_SIZE = 60\n",
    "\n",
    "train_set = simulated_Dataset(train=True)\n",
    "test_set = simulated_Dataset(train=False)\n",
    "\n",
    "train_dl = DataLoader(dataset=train_set, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_dl = DataLoader(dataset=test_set, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "for data in train_dl:\n",
    "    features, labels = data\n",
    "    print(features.shape, labels.shape)\n",
    "    break\n",
    "print(f\"Shape of single feature: {data[0][0].shape}\") # 1D tensor\n",
    "print(f\"Shape of single target: {data[1][0].shape}\") # 0D tensor (scalar)\n",
    "\n",
    "n_features = torch.flatten(data[0][0]).shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sequential_Net(nn.Module): # class inherits from nn.Module\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__() # initialize nn.Module\n",
    "        # some fully connected layers w/ linear transformation\n",
    "        \"\"\" nn.Linear(in_features, out_features, bias=True)\n",
    "        Args:\n",
    "            in_features: size of each input sample. For input shape (28, 28), \n",
    "                we would have in_features = 28 * 28 = 784\n",
    "            out_features: size of each output sample.\n",
    "        \"\"\"\n",
    "        self.fc1 = nn.Linear(n_features, 7)\n",
    "        self.fc2 = nn.Linear(7, 3)\n",
    "        self.fc3 = nn.Linear(3, 1)\n",
    "    def forward(self, x): # defines the forward propagation\n",
    "        x = F.relu(self.fc1(x)) # relu activation function\n",
    "        x = F.relu(self.fc2(x)) \n",
    "        x = F.leaky_relu(self.fc3(x))\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = Sequential_Net()\n",
    "print(network)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ds_env)",
   "language": "python",
   "name": "ds_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
