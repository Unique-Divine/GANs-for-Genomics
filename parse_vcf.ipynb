{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vcf\n",
    "\n",
    "import os\n",
    "import gzip\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.style.use(\"ggplot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VCF data loaded successfully...\n",
      "\n",
      "Metadata:\n",
      "OrderedDict([('fileformat', 'VCFv4.2'), ('fileDate', '20180201'), ('source', ['PLINKv1.90'])])\n"
     ]
    }
   ],
   "source": [
    "# VCF data loading \"hello world\"\n",
    "system_path = r\"C:\\Users\\uniqu\\Adaptation\\github repos\" \\\n",
    "              + \"\\Bioinformatics-Neural Networks for Genomic Risk\"\n",
    "system_path = system_path + r\"\\DawleyRats\"\n",
    "vcf_file_name_options = [r\"allChr.allSamps.90DR2.maf01.hweE7.noIBD.CharlesRiverOnly.vcf.gz\",\n",
    "                         r\"allChr.allSamps.90DR2.maf01.hweE7.noIBD.HarlanOnly.vcf.gz\"]\n",
    "vcf_file_name = vcf_file_name_options[0] # \"...vcf.gz\"\n",
    "\n",
    "vcf_file_path = os.path.join(system_path, vcf_file_name)\n",
    "\n",
    "vcf_reader = vcf.Reader(filename=vcf_file_path, compressed=True)\n",
    "\n",
    "try:\n",
    "    print(\"VCF data loaded successfully...\\n\")\n",
    "    print(f\"Metadata:\\n{vcf_reader.metadata}\")\n",
    "except: \n",
    "    print(\"Failed to load VCF data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "## Understanding the PyVCF library\n",
    "\n",
    "Resources Used:\n",
    "- [[PyVCF docs]](https://pyvcf.readthedocs.io/en/latest/)\n",
    "- [PyVCF Tutorial: Michal Linial (Jan, 2020). *Quantitative Biological Research with Python*.](https://youtu.be/jWu_nxlS5Vc) (ends @ 12 minutes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  `vcf.Reader` [[docs]](https://pyvcf.readthedocs.io/en/latest/API.html#vcf-reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##fileformat=VCFv4.2\n",
      "##fileDate=20180201\n",
      "##source=PLINKv1.90\n",
      "##contig=<ID=1,length=282745832>\n",
      "##contig=<ID=2,length=266367381>\n",
      "##contig=<ID=3,length=177678048>\n",
      "##contig=<ID=4,length=184213463>\n",
      "##contig=<ID=5,length=173704786>\n",
      "##contig=<ID=6,length=147965078>\n",
      "##contig=<ID=7,length=145599967>\n",
      "##contig=<ID=8,length=133288266>\n",
      "##contig=<ID=9,length=122022420>\n",
      "##contig=<ID=10,length=112580048>\n",
      "##contig=<ID=11,length=90453650>\n",
      "##contig=<ID=12,length=52683120>\n",
      "##contig=<ID=13,length=114010850>\n",
      "##contig=<ID=14,length=115436306>\n",
      "##contig=<ID=15,length=111173208>\n",
      "##contig=<ID=16,length=90610649>\n",
      "##contig=<ID=17,length=90840848>\n",
      "##contig=<ID=18,length=87963297>\n",
      "##contig=<ID=19,length=62264106>\n",
      "##contig=<ID=20,length=56089150>\n",
      "##INFO=<ID=PR,Number=0,Type=Flag,Description=\"Provisional reference allele, may not be based on real reference genome\">\n",
      "##FORMAT=<ID=GT,Number=1,Type=String,Description=\"Genotype\">\n",
      "#CHROM\tPOS\tID\tREF\tALT\tQUAL\tFILTER\tINFO\tFORMAT\t1052\t1053\t1054\t1055\t1059\t1060\t1061\t1062\t1065\t106\n"
     ]
    }
   ],
   "source": [
    "# Read the first n characters of the .gz vcf file.\n",
    "with gzip.open(vcf_file_path, 'rt') as f:\n",
    "    print(f.read(n := int(1e3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q: What's the gzip module for? [gzip docs](https://docs.python.org/3/library/gzip.html)\n",
    "\n",
    "- This module provides a simple interface to compress and decompress files like the GNU program gzip\n",
    "- `gzip`: a module that provides the `GzipFile` class as well as the `open`, `compress`, and `decompress` convenience functions.\n",
    "\n",
    "Q: The \"*.gz\" file extension?\n",
    "\n",
    "- .gz files: compressed files created using the gzip compression utility, which was created to replace and improve on compress in UNIX. This utility is commonly used on UNIX-like systems.\n",
    "- gzip file compression is often used to compress some elements of web pages to speed up page loading. \n",
    "\n",
    "Q: Why is the tool called `gzip`? \n",
    "\n",
    "- A .gz file is an archive file compressed by the standard GNU zip (gzip) compression algorithm.\n",
    "\n",
    "Q: Why use the `GzipFile` class? [class docs](https://docs.python.org/3/library/gzip.html#gzip.GzipFile)\n",
    "\n",
    "- It simulates most of the methods of a \"file object\"\n",
    "\n",
    "Q: \"file object\"? [Python docs. file object.](https://docs.python.org/3/glossary.html#term-file-object)\n",
    "\n",
    "file object: \n",
    "- An object exposing a file-oriented API (with methods such as `read()` or `write()`) to an underlying resource\n",
    "- Tutorial [file objects](https://youtu.be/Uh2ebFW8OYM)\n",
    "- Tutorial [OS Module](https://www.youtube.com/watch?v=tJxcKyFMTGo)\n",
    "\n",
    "Q: `gzip.open` method?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('fileformat', 'VCFv4.2'),\n",
       "             ('fileDate', '20180201'),\n",
       "             ('source', ['PLINKv1.90'])])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vcf_reader.metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q: How does the `OrderDict` type differ from the regular dictionary? [OrderedDict docs](https://docs.python.org/3.4/library/collections.html?highlight=ordereddict)\n",
    "- It retains the order in which the entries were added.\n",
    "\n",
    "[Python Dictionary Methods](https://www.w3schools.com/python/python_ref_dictionary.asp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_items([('fileformat', 'VCFv4.2'), ('fileDate', '20180201'), ('source', ['PLINKv1.90'])])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vcf_reader.metadata.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('fileformat', 'VCFv4.2')\n",
      "('fileDate', '20180201')\n",
      "('source', ['PLINKv1.90'])\n"
     ]
    }
   ],
   "source": [
    "for pair in vcf_reader.metadata.items():\n",
    "    print(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('PR',\n",
       "              Info(id='PR', num=0, type='Flag', desc='Provisional reference allele, may not be based on real reference genome', source=None, version=None))])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vcf_reader.infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_items([('PR', Info(id='PR', num=0, type='Flag', desc='Provisional reference allele, may not be based on real reference genome', source=None, version=None))])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vcf_reader.infos.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PR (Flag): Provisional reference allele, may not be based on real reference genome\n"
     ]
    }
   ],
   "source": [
    "# name: name of an info object\n",
    "# info: a vcf.Reader info object\n",
    "for name, info in vcf_reader.infos.items():\n",
    "    print(f\"{name} ({info.type}): {info.desc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`vcf_reader.infos` | info object:\n",
    "- `info.type`: type of the info object\n",
    "- `info.desc`: desription of the info object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `vcf.model._Record` [[docs]][record docs]\n",
    "\n",
    "**class `vcf.model._Record`**: A set of calls at a site. The standard VCF fields CHROM, POS, IS, REF, ALT, INFO, QUAL, FILTER, and FORMAT are available as properties (details on [Wikipedia][vcf_wikipedia]). \n",
    "\n",
    "The list of calls is in the `samples` attribute. \n",
    "\n",
    "[record docs]: https://pyvcf.readthedocs.io/en/latest/API.html#vcf-model-record\n",
    "[vcf_wikipedia]: https://en.wikipedia.org/wiki/Variant_Call_Format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`vcf_reader` is an iterable object.\n",
    "\n",
    "This means `it = iter(vcf_reader)` would be redundant and we can already use `next()`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chromsome: 1\n",
      "position: 175954\n",
      "alternative alleles: [C]\n",
      "reference base: G\n",
      "Variation info: {'PR': True}\n",
      "Identifier of variation: chr1.175954\n"
     ]
    }
   ],
   "source": [
    "def printRecordAttributes(vcf_reader, record=None, start=0):\n",
    "    \n",
    "    if record == None:\n",
    "        for snp_idx, record in enumerate(vcf_reader, start=0):\n",
    "            break\n",
    "        \n",
    "    print(f\"Chromsome: {record.CHROM}\")\n",
    "    print(f\"position: {record.POS}\")\n",
    "    print(f\"alternative alleles: {record.ALT}\")\n",
    "    print(f\"reference base: {record.REF}\")\n",
    "    print(f\"Variation info: {record.INFO}\")\n",
    "    print(f\"Identifier of variation: {record.ID}\")\n",
    "\n",
    "printRecordAttributes(vcf_reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def appendRecordData(record_df, record):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        record_df (pd.DataFrame): \n",
    "        record (vcf.model._Record):\n",
    "    \n",
    "    Returns:\n",
    "        (pd.DataFrame): record_df with an additional row of record (SNP) data.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Alternate allele bases\n",
    "    if len(record.ALT) == 0:\n",
    "        alt0, alt1 = np.nan, np.nan\n",
    "    elif len(record.ALT) == 1:\n",
    "        alt0, alt1 = record.ALT[0], np.nan\n",
    "\n",
    "    varIdentifier = pd.Series(record.ID, name=\"varIdentifier\")\n",
    "    \n",
    "    df = pd.DataFrame(\n",
    "        data = {\"refBase\": record.REF, \"altAllele0\": alt0,\n",
    "                \"altAllele1\": alt1},\n",
    "        index = varIdentifier)\n",
    "    \n",
    "    record_df = record_df.append(df, ignore_index=False)\n",
    "    \n",
    "    return record_df\n",
    "\n",
    "def appendCallData(call_df, record):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        call_df (pd.DataFrame):\n",
    "        record (vcf.model._Record): \n",
    "        \n",
    "    Returns:\n",
    "        (pd.DataFrame): call_df with additional columns of (SNP) data\n",
    "    \"\"\"\n",
    "\n",
    "    varIdentifier = pd.Series(record.ID, name=\"SNP\"+\"varIdentifier\")\n",
    "    sample_names = np.array([sample.sample for sample in record.samples])\n",
    "    gt_types = np.array([sample.gt_type for sample in record.samples]).reshape(1,-1)\n",
    "    \n",
    "    df = pd.DataFrame(\n",
    "        data = gt_types,\n",
    "        columns = sample_names,\n",
    "        index = varIdentifier)\n",
    "    \n",
    "    call_df = call_df.append(df, ignore_index=False)\n",
    "    \n",
    "    return call_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              refBase altAllele0  altAllele1\n",
      "varIdentifier                               \n",
      "chr1.175954         G          C         NaN\n",
      "chr1.175960         C          T         NaN\n",
      "chr1.175970         T          A         NaN\n",
      "chr1.177010         G          A         NaN\n",
      "chr1.669529         T          C         NaN \n",
      "\n",
      "\n",
      "\n",
      "                  1052  1053  1054  1055  1059  1060  1061  1062  1065  1067  \\\n",
      "SNPvarIdentifier                                                               \n",
      "chr1.175954          0     0     0     0     0     0     0     0     0     0   \n",
      "chr1.175960          0     0     0     0     0     0     0     0     0     0   \n",
      "chr1.175970          0     0     0     0     0     0     0     0     0     0   \n",
      "chr1.177010          0     0     0     0     0     0     0     0     0     0   \n",
      "chr1.669529          0     0     0     0     0     0     0     0     0     0   \n",
      "\n",
      "                  ...  2028  1482  2442  3854  2057  2494  4022  4182  4659  \\\n",
      "SNPvarIdentifier  ...                                                         \n",
      "chr1.175954       ...     0     0     0     0     0     0     0     0     0   \n",
      "chr1.175960       ...     0     0     0     0     0     0     0     0     0   \n",
      "chr1.175970       ...     0     0     0     0     0     0     0     0     0   \n",
      "chr1.177010       ...     0     1     0     0     0     0     0     0     0   \n",
      "chr1.669529       ...     0     0     0     0     0     0     1     0     1   \n",
      "\n",
      "                  920  \n",
      "SNPvarIdentifier       \n",
      "chr1.175954         0  \n",
      "chr1.175960         0  \n",
      "chr1.175970         0  \n",
      "chr1.177010         0  \n",
      "chr1.669529         0  \n",
      "\n",
      "[5 rows x 1780 columns]\n"
     ]
    }
   ],
   "source": [
    "def testAppendMethods():\n",
    "    \"\"\"Loops through the vcf file and converts the raw text data into \n",
    "    pd.DataFrame objects. \n",
    "    \"\"\"\n",
    "    vcf_reader = vcf.Reader(filename=vcf_file_path, compressed=True)\n",
    "    \n",
    "    # initialize DataFrames \n",
    "    recordAttributes = pd.DataFrame()\n",
    "    call_df = pd.DataFrame()\n",
    "\n",
    "    for snp_idx, record in enumerate(vcf_reader, start=0):\n",
    "        recordAttributes = appendRecordData(recordAttributes, record=record)\n",
    "        call_df = appendCallData(call_df, record=record) \n",
    "\n",
    "        # Stop criterion\n",
    "        if snp_idx == 5:\n",
    "            break\n",
    "\n",
    "    print(recordAttributes.head(), '\\n\\n\\n')\n",
    "    print(call_df.head())\n",
    "\n",
    "testAppendMethods()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `vcf.model_Call` [[docs]][call docs]\n",
    "\n",
    "**class `vcf.model._Call`**: A genotype call, a cell entry in a VCF file.\n",
    "\n",
    "[call docs]: https://pyvcf.readthedocs.io/en/latest/API.html#vcf-model-call\n",
    "\n",
    "### What exactly is genotype? And why is there a heterozygous property in this class?\n",
    "\n",
    "A **gene** is a section of DNA that encodes a trait. The precise arrangement of **nucleotides** in a gene can differ between copies of the same gene. Therefore, a gene can exist in different forms across organisms. These different forms are known as **alleles**. The exact fixed position on the chromosome that contains a particular gene is known as a **locus**.\n",
    "\n",
    "A **diploid** organism either inherits two copies of the same allele or one copy of two different alleles from their parents. If an individual inherits two identical alleles, their **genotype** is said to be **homozygous** at that locus. However, if they possess two different alleles, their genotype is classed as **heterozygous** for that locus.\n",
    "\n",
    "Alleles of the same gene are either autosomal dominant or recessive. An **autosomal dominant allele** will always be preferentially expressed over a recessive allele.\n",
    "\n",
    "The subsequent combination of alleles that an individual possesses for a specific gene is their **genotype**.  \n",
    "\n",
    "Nucleotides are each composed of a phosphate group, sugar and a base.\n",
    "\n",
    "[source: technologynetworks.com/genomics](https://www.technologynetworks.com/genomics/articles/genotype-vs-phenotype-examples-and-definitions-318446)\n",
    "\n",
    "### Genotype calling, genotyping, and SNP calling?\n",
    "\n",
    "What's the difference in these terms? What is \"calling\"?\n",
    "\n",
    "**Source**: [[Kevin Blighe]](https://www.biostars.org/p/277927/)\n",
    "\n",
    "#### Genotyping\n",
    "\n",
    "\n",
    "\n",
    "#### Genotype & SNP calling\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Genotype calling is the process of determining the genotype for each individual and is typically only done for positions in which a SNP or a 'variant' has already been called. We use the word 'calling' here to signify the estimation of one unique SNP or genotype.\n",
    "\n",
    "**Source**: Nielsen, R., Paul, J. S., Albrechtsen, A., & Song, Y. S. (2011). Genotype and SNP calling from next-generation sequencing data. *Nature reviews. Genetics, 12(6)*, 443â€“451. [ncbi.nlm.nih.gov](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3593722/#:~:text=Genotype%20calling%20is%20the%20process,one%20unique%20SNP%20or%20genotype)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C/C 0\n",
      "Chromsome: 1\n",
      "position: 175960\n",
      "alternative alleles: [T]\n",
      "reference base: C\n",
      "Variation info: {'PR': True}\n",
      "Identifier of variation: chr1.175960\n",
      "\n",
      "\n",
      "C\n",
      "/\n",
      "C\n",
      "C/C 0\n",
      "Chromsome: 1\n",
      "position: 175960\n",
      "alternative alleles: [T]\n",
      "reference base: C\n",
      "Variation info: {'PR': True}\n",
      "Identifier of variation: chr1.175960\n",
      "\n",
      "\n",
      "C\n",
      "/\n",
      "C\n"
     ]
    }
   ],
   "source": [
    "record = next(vcf_reader)\n",
    "for idx, sample in enumerate(record.samples):\n",
    "    print(sample.gt_bases, sample.gt_type)\n",
    "    printRecordAttributes(vcf_reader=vcf_reader, record=record)\n",
    "    print(\"\\n\")\n",
    "    char = iter(sample.gt_bases)\n",
    "    print(next(char))\n",
    "    print(next(char))\n",
    "    print(next(char))\n",
    "    \n",
    "    if idx == 1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We searched for a record with each `gt_type` to figure out what the variable meant. It's 0 if both alleles are the reference, 1 if one of them is, and 2 if both alleles are alternative alleles. \n",
    "\n",
    "```python\n",
    ">>> df = pd.DataFrame(\n",
    "        data = [[sample.sample, sample.gt_bases, \n",
    "            sample.gt_type, sample.is_het, \n",
    "            sample.phased] for sample in record.samples],\n",
    "        columns = [\"sample_name\", \"gt_bases\", \n",
    "                   \"gt_type\", \"is_het\", \"phased\"])\n",
    "\n",
    ">>> df['gt_bases'].value_counts()\n",
    "A/A    1698\n",
    "A/C      81\n",
    "C/C       1\n",
    "Name: gt_bases, dtype: int64\n",
    "        \n",
    ">>> df.groupby(\"gt_bases\")['gt_type'].value_counts()\n",
    "gt_bases  gt_type\n",
    "A/A       0          1698\n",
    "A/C       1            81\n",
    "C/C       2             1\n",
    "Name: gt_type, dtype: int64\n",
    "        \n",
    ">>> df['gt_type'].value_counts()\n",
    "0    1698\n",
    "1      81\n",
    "2       1\n",
    "Name: gt_type, dtype: int64\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(list, 1780, ['1052', '1053', '1054'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vcf_reader.samples (list): the genotype calls\n",
    "\n",
    "type(vcf_reader.samples), len(vcf_reader.samples), vcf_reader.samples[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([Call(sample=1052, CallData(GT=0/0)),\n",
       "       Call(sample=1053, CallData(GT=0/0)),\n",
       "       Call(sample=1054, CallData(GT=0/0)), ...,\n",
       "       Call(sample=4182, CallData(GT=0/0)),\n",
       "       Call(sample=4659, CallData(GT=0/0)),\n",
       "       Call(sample=920, CallData(GT=0/0))], dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(record.samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variant type: snp\n",
      "      \tTrue, False\n",
      "      \t['C', T]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Variant type: {record.var_type}\\n\\\n",
    "      \\t{record.is_snp}, {record.is_indel}\\n\\\n",
    "      \\t{record.alleles}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## The Script "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SNPs looped: 0. Time: 0 min, 0.02 s.\n",
      "---------------------------\n",
      "              refBase altAllele0  altAllele1\n",
      "varIdentifier                               \n",
      "chr1.175970         T          A         NaN\n",
      "chr1.177010         G          A         NaN\n",
      "chr1.669529         T          C         NaN\n",
      "chr1.669535         C          T         NaN\n",
      "chr1.669543         A          C         NaN \n",
      "\n",
      "\n",
      "\n",
      "                  1052  1053  1054  1055  1059  1060  1061  1062  1065  1067  \\\n",
      "SNPvarIdentifier                                                               \n",
      "chr1.175970          0     0     0     0     0     0     0     0     0     0   \n",
      "chr1.177010          0     0     0     0     0     0     0     0     0     0   \n",
      "chr1.669529          0     0     0     0     0     0     0     0     0     0   \n",
      "chr1.669535          0     0     0     0     0     0     0     0     0     0   \n",
      "chr1.669543          0     0     0     0     0     0     0     0     0     0   \n",
      "\n",
      "                  ...  2028  1482  2442  3854  2057  2494  4022  4182  4659  \\\n",
      "SNPvarIdentifier  ...                                                         \n",
      "chr1.175970       ...     0     0     0     0     0     0     0     0     0   \n",
      "chr1.177010       ...     0     1     0     0     0     0     0     0     0   \n",
      "chr1.669529       ...     0     0     0     0     0     0     1     0     1   \n",
      "chr1.669535       ...     1     1     1     1     0     0     0     0     0   \n",
      "chr1.669543       ...     0     0     0     0     0     0     1     0     1   \n",
      "\n",
      "                  920  \n",
      "SNPvarIdentifier       \n",
      "chr1.175970         0  \n",
      "chr1.177010         0  \n",
      "chr1.669529         0  \n",
      "chr1.669535         0  \n",
      "chr1.669543         0  \n",
      "\n",
      "[5 rows x 1780 columns]\n"
     ]
    }
   ],
   "source": [
    "import vcf\n",
    "\n",
    "import os\n",
    "import gzip\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.style.use(\"ggplot\")\n",
    "\n",
    "def read_chars_gz(n):\n",
    "    \"\"\" Read the first n characters of the .gz vcf file.\n",
    "    Args:\n",
    "        n (int)\n",
    "    \"\"\"\n",
    "    with gzip.open(vcf_file_path, 'rt') as f:\n",
    "        print(f.read(n))\n",
    "\n",
    "def appendRecordData(record_df, record):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        record_df (pd.DataFrame): \n",
    "        record (vcf.model._Record):\n",
    "    \n",
    "    Returns:\n",
    "        (pd.DataFrame): record_df with an additional row of record (SNP) data.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Alternate allele bases\n",
    "    if len(record.ALT) == 0:\n",
    "        alt0, alt1 = np.nan, np.nan\n",
    "    elif len(record.ALT) == 1:\n",
    "        alt0, alt1 = record.ALT[0], np.nan\n",
    "\n",
    "    varIdentifier = pd.Series(record.ID, name=\"varIdentifier\")\n",
    "    \n",
    "    df = pd.DataFrame(\n",
    "        data = {\"refBase\": record.REF, \"altAllele0\": alt0,\n",
    "                \"altAllele1\": alt1},\n",
    "        index = varIdentifier)\n",
    "    \n",
    "    record_df = record_df.append(df, ignore_index=False)\n",
    "    \n",
    "    return record_df\n",
    "\n",
    "def appendCallData(call_df, record):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        call_df (pd.DataFrame):\n",
    "        record (vcf.model._Record): \n",
    "        \n",
    "    Returns:\n",
    "        (pd.DataFrame): call_df with additional columns of (SNP) data\n",
    "    \"\"\"\n",
    "\n",
    "    varIdentifier = pd.Series(record.ID, name=\"SNP\"+\"varIdentifier\")\n",
    "    sample_names = np.array([sample.sample for sample in record.samples])\n",
    "    gt_types = np.array([sample.gt_type for sample in record.samples]).reshape(1,-1)\n",
    "    \n",
    "    df = pd.DataFrame(\n",
    "        data = gt_types,\n",
    "        columns = sample_names,\n",
    "        index = varIdentifier)\n",
    "    \n",
    "    call_df = call_df.append(df, ignore_index=False)\n",
    "    \n",
    "    return call_df\n",
    "\n",
    "def vcftoDataFrame(vcf_reader, verbose=False, test=False, save=False):\n",
    "    \"\"\"Loops through the vcf file and converts the raw text data into \n",
    "    pd.DataFrame objects. \n",
    "    \"\"\"\n",
    "    # time the operation\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # initialize DataFrames \n",
    "    recordAttributes = pd.DataFrame()\n",
    "    call_df = pd.DataFrame()\n",
    "\n",
    "    for snp_idx, record in enumerate(vcf_reader, start=0):\n",
    "        recordAttributes = appendRecordData(recordAttributes, record=record)\n",
    "        call_df = appendCallData(call_df, record=record) \n",
    "        \n",
    "        if verbose == True:\n",
    "            if (snp_idx % 1000) == 0:\n",
    "                current_time = time.time() - start_time\n",
    "                minutes = int(current_time / 60)\n",
    "                seconds = current_time % 60\n",
    "                print(f\"SNPs looped: {snp_idx}. Time: {minutes} min, {seconds:.2f} s.\")\n",
    "            if (snp_idx % 10000) == 0:\n",
    "                print(\"---------------------------\")\n",
    "\n",
    "        if test == True:\n",
    "            # Stop criterion\n",
    "            if snp_idx == 5:\n",
    "                print(recordAttributes.head(), '\\n\\n\\n')\n",
    "                print(call_df.head())\n",
    "                break\n",
    "        \n",
    "    if save == True:\n",
    "        recordAttributes.to_csv(\"recordAttributes.csv\")\n",
    "        call_df.to_csv(\"gtTypes.csv\")\n",
    "\n",
    "vcftoDataFrame(vcf_reader, test=True, verbose=True, save=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VCF data loaded successfully...\n",
      "\n",
      "Metadata:\n",
      "OrderedDict([('fileformat', 'VCFv4.2'), ('fileDate', '20180201'), ('source', ['PLINKv1.90'])])\n",
      "SNPs looped: 0. Time: 0 min, 0.03 s.\n",
      "---------------------------\n",
      "SNPs looped: 1000. Time: 0 min, 20.18 s.\n",
      "SNPs looped: 2000. Time: 0 min, 42.12 s.\n",
      "SNPs looped: 3000. Time: 1 min, 7.43 s.\n",
      "SNPs looped: 4000. Time: 1 min, 36.73 s.\n",
      "SNPs looped: 5000. Time: 2 min, 9.82 s.\n",
      "SNPs looped: 6000. Time: 2 min, 51.89 s.\n",
      "SNPs looped: 7000. Time: 3 min, 28.39 s.\n",
      "SNPs looped: 8000. Time: 4 min, 11.51 s.\n",
      "SNPs looped: 9000. Time: 4 min, 53.36 s.\n",
      "SNPs looped: 10000. Time: 5 min, 39.17 s.\n",
      "---------------------------\n",
      "SNPs looped: 11000. Time: 6 min, 27.36 s.\n",
      "SNPs looped: 12000. Time: 7 min, 18.38 s.\n",
      "SNPs looped: 13000. Time: 8 min, 20.98 s.\n",
      "SNPs looped: 14000. Time: 9 min, 16.16 s.\n",
      "SNPs looped: 15000. Time: 10 min, 14.42 s.\n",
      "SNPs looped: 16000. Time: 11 min, 18.50 s.\n",
      "SNPs looped: 17000. Time: 12 min, 22.84 s.\n",
      "SNPs looped: 18000. Time: 13 min, 28.96 s.\n",
      "SNPs looped: 19000. Time: 14 min, 43.38 s.\n",
      "SNPs looped: 20000. Time: 15 min, 58.52 s.\n",
      "---------------------------\n",
      "SNPs looped: 21000. Time: 17 min, 19.03 s.\n",
      "SNPs looped: 22000. Time: 18 min, 40.47 s.\n",
      "SNPs looped: 23000. Time: 20 min, 4.22 s.\n",
      "SNPs looped: 24000. Time: 21 min, 31.76 s.\n",
      "SNPs looped: 25000. Time: 23 min, 1.51 s.\n",
      "SNPs looped: 26000. Time: 24 min, 31.64 s.\n",
      "SNPs looped: 27000. Time: 26 min, 5.41 s.\n",
      "SNPs looped: 28000. Time: 27 min, 39.28 s.\n",
      "SNPs looped: 29000. Time: 29 min, 16.85 s.\n",
      "SNPs looped: 30000. Time: 31 min, 12.85 s.\n",
      "---------------------------\n",
      "SNPs looped: 31000. Time: 32 min, 56.54 s.\n",
      "SNPs looped: 32000. Time: 34 min, 43.91 s.\n",
      "SNPs looped: 33000. Time: 36 min, 33.80 s.\n",
      "SNPs looped: 34000. Time: 38 min, 26.10 s.\n",
      "SNPs looped: 35000. Time: 40 min, 20.71 s.\n",
      "SNPs looped: 36000. Time: 42 min, 17.11 s.\n",
      "SNPs looped: 37000. Time: 44 min, 16.77 s.\n",
      "SNPs looped: 38000. Time: 46 min, 18.21 s.\n",
      "SNPs looped: 39000. Time: 48 min, 23.38 s.\n",
      "SNPs looped: 40000. Time: 50 min, 34.18 s.\n",
      "---------------------------\n",
      "SNPs looped: 41000. Time: 52 min, 47.68 s.\n",
      "SNPs looped: 42000. Time: 55 min, 5.77 s.\n",
      "SNPs looped: 43000. Time: 57 min, 30.44 s.\n",
      "SNPs looped: 44000. Time: 59 min, 50.75 s.\n",
      "SNPs looped: 45000. Time: 62 min, 15.37 s.\n",
      "SNPs looped: 46000. Time: 64 min, 42.96 s.\n",
      "SNPs looped: 47000. Time: 67 min, 12.73 s.\n",
      "SNPs looped: 48000. Time: 69 min, 45.60 s.\n",
      "SNPs looped: 49000. Time: 72 min, 21.73 s.\n",
      "SNPs looped: 50000. Time: 74 min, 59.25 s.\n",
      "---------------------------\n",
      "SNPs looped: 51000. Time: 77 min, 40.30 s.\n",
      "SNPs looped: 52000. Time: 80 min, 23.07 s.\n",
      "SNPs looped: 53000. Time: 83 min, 9.86 s.\n",
      "SNPs looped: 54000. Time: 86 min, 0.16 s.\n",
      "SNPs looped: 55000. Time: 88 min, 53.57 s.\n",
      "SNPs looped: 56000. Time: 91 min, 49.78 s.\n",
      "SNPs looped: 57000. Time: 94 min, 46.88 s.\n",
      "SNPs looped: 58000. Time: 97 min, 48.00 s.\n",
      "SNPs looped: 59000. Time: 100 min, 52.83 s.\n",
      "SNPs looped: 60000. Time: 104 min, 0.20 s.\n",
      "---------------------------\n",
      "SNPs looped: 61000. Time: 107 min, 10.50 s.\n",
      "SNPs looped: 62000. Time: 110 min, 21.35 s.\n",
      "SNPs looped: 63000. Time: 113 min, 37.22 s.\n",
      "SNPs looped: 64000. Time: 116 min, 54.94 s.\n",
      "SNPs looped: 65000. Time: 120 min, 16.70 s.\n",
      "SNPs looped: 66000. Time: 123 min, 41.16 s.\n",
      "SNPs looped: 67000. Time: 127 min, 7.73 s.\n",
      "SNPs looped: 68000. Time: 130 min, 38.71 s.\n",
      "SNPs looped: 69000. Time: 134 min, 12.65 s.\n",
      "SNPs looped: 70000. Time: 137 min, 48.96 s.\n",
      "---------------------------\n",
      "SNPs looped: 71000. Time: 141 min, 31.74 s.\n",
      "SNPs looped: 72000. Time: 145 min, 11.42 s.\n",
      "SNPs looped: 73000. Time: 148 min, 54.40 s.\n",
      "SNPs looped: 74000. Time: 152 min, 41.97 s.\n",
      "SNPs looped: 75000. Time: 156 min, 30.36 s.\n",
      "SNPs looped: 76000. Time: 160 min, 22.80 s.\n",
      "SNPs looped: 77000. Time: 164 min, 19.94 s.\n",
      "SNPs looped: 78000. Time: 168 min, 19.07 s.\n",
      "SNPs looped: 79000. Time: 172 min, 18.44 s.\n",
      "SNPs looped: 80000. Time: 176 min, 21.46 s.\n",
      "---------------------------\n",
      "SNPs looped: 81000. Time: 180 min, 27.56 s.\n",
      "SNPs looped: 82000. Time: 184 min, 38.42 s.\n",
      "SNPs looped: 83000. Time: 188 min, 51.13 s.\n",
      "SNPs looped: 84000. Time: 193 min, 7.39 s.\n",
      "SNPs looped: 85000. Time: 197 min, 25.71 s.\n",
      "SNPs looped: 86000. Time: 201 min, 46.71 s.\n",
      "SNPs looped: 87000. Time: 206 min, 20.70 s.\n",
      "SNPs looped: 88000. Time: 211 min, 26.25 s.\n",
      "SNPs looped: 89000. Time: 216 min, 30.85 s.\n",
      "SNPs looped: 90000. Time: 221 min, 21.93 s.\n",
      "---------------------------\n",
      "SNPs looped: 91000. Time: 226 min, 17.12 s.\n",
      "SNPs looped: 92000. Time: 231 min, 21.32 s.\n",
      "SNPs looped: 93000. Time: 236 min, 28.10 s.\n",
      "SNPs looped: 94000. Time: 241 min, 40.32 s.\n",
      "SNPs looped: 95000. Time: 246 min, 53.44 s.\n",
      "SNPs looped: 96000. Time: 252 min, 5.86 s.\n",
      "SNPs looped: 97000. Time: 257 min, 25.74 s.\n",
      "SNPs looped: 98000. Time: 262 min, 40.80 s.\n",
      "SNPs looped: 99000. Time: 268 min, 6.34 s.\n",
      "SNPs looped: 100000. Time: 273 min, 38.40 s.\n",
      "---------------------------\n",
      "SNPs looped: 101000. Time: 279 min, 29.59 s.\n",
      "SNPs looped: 102000. Time: 285 min, 11.90 s.\n",
      "SNPs looped: 103000. Time: 291 min, 1.08 s.\n",
      "SNPs looped: 104000. Time: 296 min, 20.48 s.\n",
      "SNPs looped: 105000. Time: 301 min, 41.29 s.\n",
      "SNPs looped: 106000. Time: 307 min, 9.19 s.\n",
      "SNPs looped: 107000. Time: 312 min, 35.23 s.\n",
      "SNPs looped: 108000. Time: 318 min, 5.49 s.\n",
      "SNPs looped: 109000. Time: 323 min, 39.12 s.\n",
      "SNPs looped: 110000. Time: 329 min, 12.49 s.\n",
      "---------------------------\n",
      "SNPs looped: 111000. Time: 334 min, 46.64 s.\n",
      "SNPs looped: 112000. Time: 340 min, 21.38 s.\n",
      "SNPs looped: 113000. Time: 345 min, 57.49 s.\n",
      "SNPs looped: 114000. Time: 351 min, 39.48 s.\n",
      "SNPs looped: 115000. Time: 357 min, 24.00 s.\n",
      "SNPs looped: 116000. Time: 363 min, 10.51 s.\n",
      "SNPs looped: 117000. Time: 369 min, 3.26 s.\n",
      "SNPs looped: 118000. Time: 374 min, 55.91 s.\n",
      "SNPs looped: 119000. Time: 380 min, 52.41 s.\n",
      "SNPs looped: 120000. Time: 386 min, 52.30 s.\n",
      "---------------------------\n",
      "SNPs looped: 121000. Time: 392 min, 55.20 s.\n",
      "SNPs looped: 122000. Time: 399 min, 0.76 s.\n",
      "SNPs looped: 123000. Time: 405 min, 8.41 s.\n",
      "SNPs looped: 124000. Time: 411 min, 20.04 s.\n",
      "SNPs looped: 125000. Time: 417 min, 33.10 s.\n",
      "SNPs looped: 126000. Time: 423 min, 50.88 s.\n",
      "SNPs looped: 127000. Time: 430 min, 10.96 s.\n",
      "SNPs looped: 128000. Time: 436 min, 33.35 s.\n",
      "SNPs looped: 129000. Time: 442 min, 58.52 s.\n",
      "SNPs looped: 130000. Time: 449 min, 27.51 s.\n",
      "---------------------------\n",
      "SNPs looped: 131000. Time: 456 min, 0.10 s.\n",
      "SNPs looped: 132000. Time: 462 min, 35.73 s.\n",
      "SNPs looped: 133000. Time: 469 min, 34.47 s.\n",
      "SNPs looped: 134000. Time: 476 min, 10.98 s.\n",
      "SNPs looped: 135000. Time: 482 min, 53.79 s.\n",
      "SNPs looped: 136000. Time: 489 min, 39.44 s.\n",
      "SNPs looped: 137000. Time: 496 min, 24.55 s.\n",
      "SNPs looped: 138000. Time: 503 min, 15.14 s.\n",
      "SNPs looped: 139000. Time: 510 min, 7.08 s.\n",
      "SNPs looped: 140000. Time: 517 min, 1.19 s.\n",
      "---------------------------\n",
      "SNPs looped: 141000. Time: 523 min, 58.48 s.\n",
      "SNPs looped: 142000. Time: 530 min, 57.19 s.\n",
      "SNPs looped: 143000. Time: 537 min, 58.72 s.\n",
      "SNPs looped: 144000. Time: 545 min, 5.27 s.\n",
      "SNPs looped: 145000. Time: 552 min, 14.54 s.\n",
      "SNPs looped: 146000. Time: 559 min, 26.53 s.\n",
      "SNPs looped: 147000. Time: 566 min, 41.52 s.\n",
      "SNPs looped: 148000. Time: 573 min, 58.31 s.\n",
      "SNPs looped: 149000. Time: 581 min, 18.13 s.\n",
      "SNPs looped: 150000. Time: 588 min, 38.60 s.\n",
      "---------------------------\n",
      "SNPs looped: 151000. Time: 596 min, 2.64 s.\n",
      "SNPs looped: 152000. Time: 604 min, 20.81 s.\n",
      "SNPs looped: 153000. Time: 613 min, 23.76 s.\n",
      "SNPs looped: 154000. Time: 622 min, 15.04 s.\n",
      "SNPs looped: 155000. Time: 631 min, 20.21 s.\n",
      "SNPs looped: 156000. Time: 640 min, 7.43 s.\n",
      "SNPs looped: 157000. Time: 648 min, 5.13 s.\n",
      "SNPs looped: 158000. Time: 656 min, 31.64 s.\n",
      "SNPs looped: 159000. Time: 664 min, 44.49 s.\n",
      "SNPs looped: 160000. Time: 672 min, 57.58 s.\n",
      "---------------------------\n",
      "SNPs looped: 161000. Time: 680 min, 56.51 s.\n",
      "SNPs looped: 162000. Time: 688 min, 56.98 s.\n",
      "SNPs looped: 163000. Time: 696 min, 58.16 s.\n",
      "SNPs looped: 164000. Time: 705 min, 2.22 s.\n",
      "SNPs looped: 165000. Time: 713 min, 10.11 s.\n",
      "SNPs looped: 166000. Time: 721 min, 21.13 s.\n",
      "SNPs looped: 167000. Time: 729 min, 38.71 s.\n",
      "SNPs looped: 168000. Time: 737 min, 58.68 s.\n",
      "SNPs looped: 169000. Time: 746 min, 18.87 s.\n",
      "SNPs looped: 170000. Time: 754 min, 38.82 s.\n",
      "---------------------------\n",
      "SNPs looped: 171000. Time: 763 min, 14.91 s.\n",
      "SNPs looped: 172000. Time: 771 min, 36.94 s.\n",
      "SNPs looped: 173000. Time: 780 min, 1.05 s.\n",
      "SNPs looped: 174000. Time: 788 min, 24.49 s.\n",
      "SNPs looped: 175000. Time: 796 min, 54.26 s.\n",
      "SNPs looped: 176000. Time: 805 min, 25.74 s.\n",
      "SNPs looped: 177000. Time: 814 min, 0.48 s.\n",
      "SNPs looped: 178000. Time: 822 min, 37.09 s.\n",
      "SNPs looped: 179000. Time: 831 min, 15.96 s.\n",
      "SNPs looped: 180000. Time: 840 min, 0.54 s.\n",
      "---------------------------\n",
      "SNPs looped: 181000. Time: 848 min, 50.46 s.\n",
      "SNPs looped: 182000. Time: 857 min, 39.88 s.\n",
      "SNPs looped: 183000. Time: 866 min, 30.33 s.\n",
      "SNPs looped: 184000. Time: 875 min, 25.20 s.\n",
      "SNPs looped: 185000. Time: 884 min, 22.98 s.\n",
      "SNPs looped: 186000. Time: 893 min, 24.03 s.\n",
      "SNPs looped: 187000. Time: 902 min, 28.30 s.\n",
      "SNPs looped: 188000. Time: 911 min, 37.41 s.\n",
      "SNPs looped: 189000. Time: 920 min, 46.23 s.\n",
      "SNPs looped: 190000. Time: 929 min, 59.80 s.\n",
      "---------------------------\n",
      "SNPs looped: 191000. Time: 939 min, 15.79 s.\n",
      "SNPs looped: 192000. Time: 948 min, 36.42 s.\n",
      "SNPs looped: 193000. Time: 957 min, 58.47 s.\n",
      "SNPs looped: 194000. Time: 967 min, 24.97 s.\n",
      "SNPs looped: 195000. Time: 976 min, 54.21 s.\n",
      "SNPs looped: 196000. Time: 986 min, 24.47 s.\n",
      "SNPs looped: 197000. Time: 996 min, 4.50 s.\n",
      "SNPs looped: 198000. Time: 1006 min, 39.89 s.\n",
      "SNPs looped: 199000. Time: 1016 min, 55.61 s.\n",
      "SNPs looped: 200000. Time: 1027 min, 33.26 s.\n",
      "---------------------------\n",
      "SNPs looped: 201000. Time: 1038 min, 4.28 s.\n",
      "SNPs looped: 202000. Time: 1048 min, 21.96 s.\n",
      "SNPs looped: 203000. Time: 1058 min, 43.89 s.\n",
      "SNPs looped: 204000. Time: 1069 min, 34.02 s.\n",
      "SNPs looped: 205000. Time: 1081 min, 30.46 s.\n",
      "SNPs looped: 206000. Time: 1094 min, 33.28 s.\n",
      "SNPs looped: 207000. Time: 1105 min, 52.40 s.\n",
      "SNPs looped: 208000. Time: 1116 min, 59.00 s.\n",
      "SNPs looped: 209000. Time: 1128 min, 7.71 s.\n",
      "SNPs looped: 210000. Time: 1140 min, 43.07 s.\n",
      "---------------------------\n",
      "SNPs looped: 211000. Time: 1153 min, 30.01 s.\n",
      "SNPs looped: 212000. Time: 1163 min, 51.10 s.\n",
      "SNPs looped: 213000. Time: 1174 min, 9.95 s.\n",
      "SNPs looped: 214000. Time: 1184 min, 32.23 s.\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    \n",
    "    system_path = r\"C:\\Users\\uniqu\\Adaptation\\github repos\" \\\n",
    "              + \"\\Bioinformatics-Neural Networks for Genomic Risk\"\n",
    "    system_path = system_path + r\"\\DawleyRats\"\n",
    "    vcf_file_options = {\n",
    "        \"CharlesRiver\": r\"allChr.allSamps.90DR2.maf01.hweE7.noIBD.CharlesRiverOnly.vcf.gz\",\n",
    "        \"Harlan\": r\"allChr.allSamps.90DR2.maf01.hweE7.noIBD.HarlanOnly.vcf.gz\"}\n",
    "    vcf_file_name = vcf_file_options[\"CharlesRiver\"] # \"...vcf.gz\"\n",
    "    vcf_file_path = os.path.join(system_path, vcf_file_name)\n",
    "    vcf_reader = vcf.Reader(filename=vcf_file_path, compressed=True)\n",
    "\n",
    "    try:\n",
    "        print(\"VCF data loaded successfully...\\n\")\n",
    "        print(f\"Metadata:\\n{vcf_reader.metadata}\")\n",
    "    except: \n",
    "        print(\"Failed to load VCF data.\")    \n",
    "        \n",
    "    vcftoDataFrame(vcf_reader, test=False, verbose=True, save=True)    \n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
